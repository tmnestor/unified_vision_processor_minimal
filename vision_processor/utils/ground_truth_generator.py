"""Ground Truth Generator for Synthetic Invoices

Generates ground truth annotations alongside synthetic invoice images,
creating a complete evaluation dataset with known correct answers.
"""

import csv
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional


class GroundTruthGenerator:
    """Generate ground truth data for synthetic invoices."""

    def __init__(self, output_dir: str = "./ground_truth"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.ground_truth_file = self.output_dir / "ground_truth.csv"
        self.json_dir = self.output_dir / "json"
        self.json_dir.mkdir(exist_ok=True)

        # Expected fields from model_comparison.yaml
        self.expected_fields = [
            "DOCUMENT_TYPE",
            "SUPPLIER",
            "ABN",
            "PAYER_NAME",
            "PAYER_ADDRESS",
            "PAYER_PHONE",
            "PAYER_EMAIL",
            "INVOICE_DATE",
            "DUE_DATE",
            "GST",
            "TOTAL",
            "SUBTOTAL",
            "SUPPLIER_WEBSITE",
            "QUANTITIES",
            "PRICES",
            "BUSINESS_ADDRESS",
            "BUSINESS_PHONE",
            "BANK_NAME",
            "BSB_NUMBER",
            "BANK_ACCOUNT_NUMBER",
            "ACCOUNT_HOLDER",
            "STATEMENT_PERIOD",
            "OPENING_BALANCE",
            "CLOSING_BALANCE",
            "DESCRIPTIONS",
        ]

        # Initialize CSV with headers if it doesn't exist
        if not self.ground_truth_file.exists():
            self._init_csv()

    def _init_csv(self):
        """Initialize the ground truth CSV file with headers."""
        with self.ground_truth_file.open("w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(
                f, fieldnames=["image_filename"] + self.expected_fields
            )
            writer.writeheader()

    def save_ground_truth(
        self, image_filename: str, invoice_data: Dict
    ) -> Dict[str, str]:
        """Save ground truth data for a generated invoice.

        Args:
            image_filename: Name of the generated invoice image
            invoice_data: Dictionary containing all invoice data from generator

        Returns:
            Dictionary of ground truth field mappings
        """
        # Map invoice_data to expected fields (based on synthetic_invoice_generator.py structure)
        ground_truth = {
            "image_filename": image_filename,
            "DOCUMENT_TYPE": invoice_data.get("document_type", "INVOICE"),
            "SUPPLIER": invoice_data.get("business_name", "N/A"),
            "ABN": invoice_data.get("abn", "N/A"),
            "PAYER_NAME": invoice_data.get("payer_name", "N/A"),
            "PAYER_ADDRESS": invoice_data.get("payer_address", "N/A"),
            "PAYER_PHONE": invoice_data.get("payer_phone", "N/A"),
            "PAYER_EMAIL": invoice_data.get("payer_email", "N/A"),
            "INVOICE_DATE": invoice_data.get("date", "N/A"),  # From transaction date
            "DUE_DATE": invoice_data.get("due_date", "N/A"),
            "GST": f"${invoice_data.get('gst', 0):.2f}"
            if invoice_data.get("gst")
            else "N/A",
            "TOTAL": f"${invoice_data.get('total', 0):.2f}"
            if invoice_data.get("total")
            else "N/A",
            "SUBTOTAL": f"${invoice_data.get('subtotal', 0):.2f}"
            if invoice_data.get("subtotal")
            else "N/A",
            "SUPPLIER_WEBSITE": "N/A",  # Not generated by synthetic generator
            "QUANTITIES": invoice_data.get(
                "quantities", "N/A"
            ),  # Already formatted as string
            "PRICES": invoice_data.get("prices", "N/A"),  # Already formatted as string
            "BUSINESS_ADDRESS": invoice_data.get("business_address", "N/A"),
            "BUSINESS_PHONE": invoice_data.get("business_phone", "N/A"),
            "BANK_NAME": "N/A",  # Not generated by synthetic generator
            "BSB_NUMBER": invoice_data.get("bsb", "N/A"),
            "BANK_ACCOUNT_NUMBER": invoice_data.get(
                "bank_account", "N/A"
            ),  # Combined format
            "ACCOUNT_HOLDER": "N/A",  # Not generated by synthetic generator
            "STATEMENT_PERIOD": "N/A",  # Not applicable for invoices
            "OPENING_BALANCE": "N/A",  # Not applicable for invoices
            "CLOSING_BALANCE": "N/A",  # Not applicable for invoices
            "DESCRIPTIONS": invoice_data.get("items_list", "N/A"),  # Item names joined
        }

        # Append to CSV
        with self.ground_truth_file.open("a", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(
                f, fieldnames=["image_filename"] + self.expected_fields
            )
            writer.writerow(ground_truth)

        # Save detailed JSON for reference
        json_path = self.json_dir / f"{Path(image_filename).stem}.json"
        with json_path.open("w", encoding="utf-8") as f:
            json.dump(
                {
                    "image_filename": image_filename,
                    "invoice_data": invoice_data,
                    "ground_truth": ground_truth,
                    "generated_at": datetime.now().isoformat(),
                },
                f,
                indent=2,
                ensure_ascii=False,
            )

        return ground_truth

    def load_ground_truth(self, image_filename: Optional[str] = None) -> List[Dict]:
        """Load ground truth data from CSV.

        Args:
            image_filename: If provided, return only ground truth for this image

        Returns:
            List of ground truth dictionaries
        """
        ground_truth_data = []

        with self.ground_truth_file.open("r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            for row in reader:
                if image_filename is None or row["image_filename"] == image_filename:
                    ground_truth_data.append(row)

        return ground_truth_data

    def evaluate_extraction(self, image_filename: str, extracted_fields: Dict) -> Dict:
        """Evaluate extracted fields against ground truth.

        Args:
            image_filename: Name of the image
            extracted_fields: Dictionary of fields extracted by model

        Returns:
            Evaluation metrics dictionary
        """
        ground_truth = self.load_ground_truth(image_filename)
        if not ground_truth:
            return {"error": f"No ground truth found for {image_filename}"}

        gt = ground_truth[0]  # Get first match

        # Calculate metrics
        correct_fields = 0
        total_fields = 0
        field_results = {}

        for field in self.expected_fields:
            gt_value = gt.get(field, "N/A")
            extracted_value = extracted_fields.get(field, "N/A")

            # Normalize for comparison
            gt_normalized = str(gt_value).strip().lower()
            extracted_normalized = str(extracted_value).strip().lower()

            # Check if field matches
            is_correct = False
            if gt_normalized == extracted_normalized:
                is_correct = True
            elif gt_normalized != "n/a" and extracted_normalized != "n/a":
                # Fuzzy matching for addresses, names, etc.
                if self._fuzzy_match(gt_normalized, extracted_normalized, field):
                    is_correct = True

            if is_correct and gt_normalized != "n/a":
                correct_fields += 1

            if gt_normalized != "n/a":
                total_fields += 1

            field_results[field] = {
                "ground_truth": gt_value,
                "extracted": extracted_value,
                "correct": is_correct,
            }

        accuracy = (correct_fields / total_fields * 100) if total_fields > 0 else 0

        return {
            "image_filename": image_filename,
            "accuracy_percentage": round(accuracy, 2),
            "correct_fields": correct_fields,
            "total_fields": total_fields,
            "field_results": field_results,
        }

    def _fuzzy_match(self, gt_value: str, extracted_value: str, field: str) -> bool:
        """Perform fuzzy matching for certain field types.

        Args:
            gt_value: Ground truth value (normalized)
            extracted_value: Extracted value (normalized)
            field: Field name for context

        Returns:
            True if values are considered a match
        """
        # For amounts, check numeric equivalence
        if field in ["GST", "TOTAL", "SUBTOTAL", "OPENING_BALANCE", "CLOSING_BALANCE"]:
            # Extract numeric values
            import re

            gt_num = re.findall(r"[\d.]+", gt_value)
            ext_num = re.findall(r"[\d.]+", extracted_value)
            if gt_num and ext_num:
                try:
                    return abs(float(gt_num[0]) - float(ext_num[0])) < 0.01
                except ValueError:
                    pass

        # For addresses, check if key parts match
        if field in ["PAYER_ADDRESS", "BUSINESS_ADDRESS"]:
            # Check if main components are present
            gt_parts = set(gt_value.split())
            ext_parts = set(extracted_value.split())
            common_parts = gt_parts.intersection(ext_parts)
            if len(common_parts) >= len(gt_parts) * 0.7:  # 70% match
                return True

        # For lists (quantities, prices, descriptions), check set overlap
        if field in ["QUANTITIES", "PRICES", "DESCRIPTIONS"]:
            gt_items = set(item.strip() for item in gt_value.split(","))
            ext_items = set(item.strip() for item in extracted_value.split(","))
            if gt_items == ext_items:
                return True

        return False

    def generate_evaluation_report(self, results: List[Dict]) -> Dict:
        """Generate a comprehensive evaluation report.

        Args:
            results: List of evaluation results from evaluate_extraction

        Returns:
            Summary report dictionary
        """
        if not results:
            return {"error": "No results to evaluate"}

        # Calculate overall metrics
        total_accuracy = sum(r["accuracy_percentage"] for r in results) / len(results)

        # Calculate per-field accuracy
        field_accuracies = {}
        for field in self.expected_fields:
            field_correct = sum(
                1
                for r in results
                if r["field_results"][field]["correct"]
                and r["field_results"][field]["ground_truth"] != "N/A"
            )
            field_total = sum(
                1 for r in results if r["field_results"][field]["ground_truth"] != "N/A"
            )

            if field_total > 0:
                field_accuracies[field] = round(field_correct / field_total * 100, 2)
            else:
                field_accuracies[field] = "N/A"

        return {
            "summary": {
                "total_images": len(results),
                "overall_accuracy": round(total_accuracy, 2),
                "average_correct_fields": round(
                    sum(r["correct_fields"] for r in results) / len(results), 2
                ),
            },
            "field_accuracies": field_accuracies,
            "best_performing_fields": sorted(
                [
                    (f, acc)
                    for f, acc in field_accuracies.items()
                    if isinstance(acc, (int, float))
                ],
                key=lambda x: x[1],
                reverse=True,
            )[:5],
            "worst_performing_fields": sorted(
                [
                    (f, acc)
                    for f, acc in field_accuracies.items()
                    if isinstance(acc, (int, float))
                ],
                key=lambda x: x[1],
            )[:5],
        }
