{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f893fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, MllamaForConditionalGeneration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e49a0f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de23e8f0ef343eebc1f8c8cc2104844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"/home/jovyan/nfs_share/models/Llama-3.2-11B-Vision-Instruct\"\n",
    "# here, specify the name of the image\n",
    "imageName = \"/home/jovyan/nfs_share/tod/datasets/synthetic_invoice_014.png\"\n",
    "\n",
    "model = MllamaForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# open the image\n",
    "image = Image.open(imageName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "430be3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a message data structure\n",
    "# messageDataStructure = [\n",
    "#     {\n",
    "#         \"role\": \"user\",\n",
    "#         \"content\": [\n",
    "#             {\"type\": \"image\"},\n",
    "#             {\n",
    "#                 \"type\": \"text\",\n",
    "#                 \"text\": \"What type of document is this?\",\n",
    "#             },\n",
    "#         ],\n",
    "#     }\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1ebbc77-bc11-44c6-bd5e-35d756a2f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "messageDataStructure = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"How much did Jessica pay?\",\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b5b814e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "<|image|>How much did Jessica pay?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "**Calculating the Total Amount Paid by Jessica**\n",
      "\n",
      "To determine the total amount paid by Jessica, we need to add up the costs of all items purchased and subtract any applicable taxes.\n",
      "\n",
      "**Itemized Costs:**\n",
      "\n",
      "*   Milk 2L: $4.80\n",
      "*   Apples (kg): $3.96\n",
      "*   Ground Beef 500g: $8.90\n",
      "*   Pasta 500g: $2.90\n",
      "\n",
      "**Total Cost Before Tax:**\n",
      "$4.80 + $3.96 + $8.90 + $2.90 = $20.56\n",
      "\n",
      "**GST 10% Tax:**\n",
      "$20.56 x 0.10 = $2.06\n",
      "\n",
      "**Subtotal (including tax):**\n",
      "$20.56 + $2.06 = $22.62\n",
      "\n",
      "**Total Amount Paid:**\n",
      "$22.62 + $28.48 (GST) = $31.33\n",
      "\n",
      "Therefore, Jessica paid a total of **$31.33**.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# create text input\n",
    "textInput = processor.apply_chat_template(\n",
    "    messageDataStructure, add_generation_prompt=True\n",
    ")\n",
    "# call the processor\n",
    "inputs = processor(image, textInput, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# here, change the number of tokens to get a more detailed answer\n",
    "output = model.generate(**inputs, max_new_tokens=2000)\n",
    "# here, we decode and store the response so we can print it\n",
    "generatedOutput = processor.decode(output[0])\n",
    "\n",
    "print(generatedOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4259d5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the answer in a file\n",
    "with Path(\"/home/jovyan/nfs_share/tod/output/llama_output.txt\").open(\n",
    "    \"w\", encoding=\"utf-8\"\n",
    ") as text_file:\n",
    "    text_file.write(generatedOutput)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (unified_vision_processor)",
   "language": "python",
   "name": "unified_vision_processor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
