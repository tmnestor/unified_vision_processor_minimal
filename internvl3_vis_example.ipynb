{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Model loading - Simple InternVL3 approach (from official docs)\nfrom pathlib import Path\nimport torch\nfrom PIL import Image\nfrom transformers import AutoModel, AutoTokenizer\nimport torchvision.transforms as T\n\n# Use path from model_comparison.yaml\nmodel_id = \"/home/jovyan/nfs_share/models/InternVL3-2B\"\nimageName = \"/home/jovyan/nfs_share/tod/datasets/synthetic_invoice_014.png\"\n\nprint(\"üîß Loading InternVL3 model...\")\n\n# Load model with official recommended settings\nmodel = AutoModel.from_pretrained(\n    model_id,\n    torch_dtype=torch.bfloat16,  # Key: bfloat16, not float16!\n    low_cpu_mem_usage=True,\n    trust_remote_code=True\n).eval().cuda()\n\n# Load tokenizer with official settings\ntokenizer = AutoTokenizer.from_pretrained(\n    model_id, \n    trust_remote_code=True, \n    use_fast=False  # Important for InternVL3\n)\n\nprint(\"‚úÖ Model and tokenizer loaded successfully\")\n\n# Load image\nimage = Image.open(imageName)\nprint(f\"üì∑ Image loaded: {image.size}\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Simple image processing (from official InternVL3 docs)\ndef load_image(image, input_size=448):\n    \"\"\"Simple image preprocessing following official InternVL3 docs\"\"\"\n    transform = T.Compose([\n        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n        T.Resize((input_size, input_size)),\n        T.ToTensor(),\n        T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n    ])\n    return transform(image).unsqueeze(0).to(torch.bfloat16).cuda()\n\n# Process image\nprint(\"üñºÔ∏è  Processing image...\")\npixel_values = load_image(image)\nprint(f\"‚úÖ Image processed: {pixel_values.shape}\")\n\n# Question with official format\nquestion = '<image>\\nHow much did Jessica pay?'  # Key: <image>\\n prefix!\nprint(f\"‚ùì Question: {question}\")\n\n# Generation config\ngeneration_config = dict(max_new_tokens=2000, do_sample=True)\n\n# Generate response using simple official API\nprint(\"ü§ñ Generating response...\")\ntry:\n    response = model.chat(tokenizer, pixel_values, question, generation_config)\n    print(\"‚úÖ Response generated successfully!\")\n    print(\"\\n\" + \"=\"*50)\n    print(\"RESPONSE:\")\n    print(response)\n    print(\"=\"*50)\n    \nexcept Exception as e:\n    print(f\"‚ùå Error during inference: {e}\")\n    print(f\"Error type: {type(e).__name__}\")\n    import traceback\n    traceback.print_exc()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save response to file  \noutput_path = Path(\"/home/jovyan/nfs_share/tod/output/internvl3_output.txt\")\n\ntry:\n    # Ensure output directory exists\n    output_path.parent.mkdir(parents=True, exist_ok=True)\n    \n    # Write response to file\n    with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n        text_file.write(response)\n    \n    print(f\"‚úÖ Response saved to: {output_path}\")\n    print(f\"üìÑ File size: {output_path.stat().st_size} bytes\")\n    \nexcept NameError:\n    print(\"‚ùå Error: 'response' variable not defined.\")\n    print(\"üí° Please run Cell [3] first to generate the response.\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Error saving file: {e}\")\n    print(f\"üí° Check if directory exists: {output_path.parent}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (unified_vision_processor)",
   "language": "python",
   "name": "unified_vision_processor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}