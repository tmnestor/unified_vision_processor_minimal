{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell 1: Environment Setup and Model Loading for Llama Vision Key-Value Extraction\n",
    "\n",
    "Purpose:\n",
    "- Import all required libraries for Llama-3.2-11B-Vision-Instruct model\n",
    "- Load the Llama Vision model optimized for structured key-value extraction\n",
    "- Initialize model with proper configuration for document analysis\n",
    "- Define global configuration variables for data paths\n",
    "\n",
    "Key Components:\n",
    "- torch.bfloat16: Memory-efficient 16-bit floating point for better performance\n",
    "- device_map=\"auto\": Automatic device mapping for optimal GPU utilization\n",
    "- AutoProcessor: Handles both text and image processing for Llama Vision\n",
    "- Optimized for multimodal document understanding\n",
    "\n",
    "Global Configuration:\n",
    "- data_dir: Centralized data directory path for all image operations\n",
    "- model_path: Local path to Llama-3.2-11B-Vision-Instruct model files\n",
    "- output_dir: Directory for saving extraction results\n",
    "\n",
    "Specialized for Key-Value Extraction:\n",
    "- Optimized for structured document processing\n",
    "- Configured for business document analysis workflows\n",
    "- Supports multimodal conversation format required by Llama Vision\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, MllamaForConditionalGeneration\n",
    "\n",
    "# Global configuration variables\n",
    "data_dir = \"/home/jovyan/nfs_share/tod/huaifeng_data\"\n",
    "model_path = \"/home/jovyan/nfs_share/models/Llama-3.2-11B-Vision-Instruct\"\n",
    "output_dir = \"/home/jovyan/nfs_share/tod/output\"\n",
    "\n",
    "print(f\"üóÇÔ∏è  Data directory: {data_dir}\")\n",
    "print(f\"üìÅ Output directory: {output_dir}\")\n",
    "print(f\"üîß Loading Llama-3.2-11B-Vision-Instruct model for key-value extraction from: {model_path}\")\n",
    "\n",
    "# Load Llama Vision model with optimal configuration\n",
    "model = MllamaForConditionalGeneration.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.bfloat16,  # Use bfloat16 for memory efficiency\n",
    "    device_map=\"auto\",           # Automatic device mapping for multi-GPU support\n",
    ")\n",
    "\n",
    "# Load processor for handling both text and image inputs\n",
    "processor = AutoProcessor.from_pretrained(model_path)\n",
    "\n",
    "print(\"‚úÖ Llama Vision model and processor loaded successfully for key-value extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell 2: Document Loading and Preprocessing for Llama Vision\n",
    "\n",
    "Purpose:\n",
    "- Load and preprocess business documents for key-value extraction\n",
    "- Handle various document formats with proper image processing\n",
    "- Prepare documents for Llama Vision's multimodal processing pipeline\n",
    "\n",
    "Document Processing Features:\n",
    "- Supports various image formats (PNG, JPG, PDF conversions)\n",
    "- Handles different document orientations and sizes\n",
    "- Maintains image quality for optimal text recognition\n",
    "- Uses global data_dir for consistent path management\n",
    "\n",
    "Llama Vision Specific:\n",
    "- No complex tiling required (unlike InternVL3)\n",
    "- Direct image processing through AutoProcessor\n",
    "- Optimized for single-image document analysis\n",
    "- Maintains original aspect ratios for better text recognition\n",
    "\"\"\"\n",
    "\n",
    "def load_document_image(image_path):\n",
    "    \"\"\"\n",
    "    Load document image with path flexibility\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to document file (relative to data_dir or absolute)\n",
    "    \n",
    "    Returns:\n",
    "        PIL.Image: Loaded document image ready for processing\n",
    "    \"\"\"\n",
    "    # Handle both relative and absolute paths\n",
    "    if not image_path.startswith('/'):\n",
    "        image_path = f\"{data_dir}/{image_path}\"\n",
    "    \n",
    "    return Image.open(image_path)\n",
    "\n",
    "# Load and analyze document using global data_dir\n",
    "document_image = \"invoice.png\"  # Configurable document filename\n",
    "print(f\"üìÑ Loading document from: {data_dir}/{document_image}\")\n",
    "\n",
    "# Load document image\n",
    "image = load_document_image(document_image)\n",
    "print(f\"üì∑ Document loaded successfully: {image.size}\")\n",
    "print(f\"üìê Document aspect ratio: {image.size[0]/image.size[1]:.2f}\")\n",
    "print(f\"üñºÔ∏è  Image format: {image.format}\")\n",
    "print(f\"üé® Color mode: {image.mode}\")\n",
    "print(\"üîç Document ready for Llama Vision key-value extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell 3: Advanced Key-Value Extraction Prompt Configuration\n",
    "\n",
    "Purpose:\n",
    "- Define comprehensive prompt for extracting structured business document data\n",
    "- Configure extraction parameters for consistent, standardized output\n",
    "- Leverage Llama Vision's advanced reasoning capabilities for document analysis\n",
    "\n",
    "Enhanced Prompt Features:\n",
    "- 25 predefined fields covering comprehensive business document types\n",
    "- Advanced formatting constraints to prevent Llama's markdown tendencies\n",
    "- Explicit instructions optimized for Llama Vision's capabilities\n",
    "- Deterministic field ordering for automated downstream processing\n",
    "\n",
    "Field Categories (Comprehensive Coverage):\n",
    "1. Document metadata (type, dates, references)\n",
    "2. Supplier/business information (name, address, contact details)\n",
    "3. Financial data (amounts, GST, totals, subtotals)\n",
    "4. Transaction details (quantities, prices, descriptions)\n",
    "5. Banking information (account numbers, BSB, balances)\n",
    "\n",
    "Advanced Output Quality Controls:\n",
    "- Multiple examples of correct/incorrect formatting\n",
    "- Explicit markdown prevention (critical for Llama models)\n",
    "- Field count validation (exactly 25 lines)\n",
    "- Structured validation for downstream processing systems\n",
    "- Clear start/stop instructions to prevent conversation artifacts\n",
    "\"\"\"\n",
    "\n",
    "# Enhanced key-value extraction prompt optimized for Llama Vision\n",
    "extraction_prompt = \"\"\"Extract key-value data from this business document image.\n",
    "\n",
    "CRITICAL INSTRUCTIONS:\n",
    "- Output ONLY the structured data below\n",
    "- Do NOT include any conversation text\n",
    "- Do NOT repeat the user's request\n",
    "- Do NOT include <image> tokens\n",
    "- Start immediately with DOCUMENT_TYPE\n",
    "- Stop immediately after DESCRIPTIONS\n",
    "\n",
    "REQUIRED OUTPUT FORMAT - EXACTLY 25 LINES:\n",
    "DOCUMENT_TYPE: [value or N/A]\n",
    "SUPPLIER: [value or N/A]\n",
    "ABN: [11-digit Australian Business Number or N/A]\n",
    "PAYER_NAME: [value or N/A]\n",
    "PAYER_ADDRESS: [value or N/A]\n",
    "PAYER_PHONE: [value or N/A]\n",
    "PAYER_EMAIL: [value or N/A]\n",
    "INVOICE_DATE: [value or N/A]\n",
    "DUE_DATE: [value or N/A]\n",
    "GST: [GST amount in dollars or N/A]\n",
    "TOTAL: [total amount in dollars or N/A]\n",
    "SUBTOTAL: [subtotal amount in dollars or N/A]\n",
    "SUPPLIER_WEBSITE: [value or N/A]\n",
    "QUANTITIES: [list of quantities or N/A]\n",
    "PRICES: [individual prices in dollars or N/A]\n",
    "BUSINESS_ADDRESS: [value or N/A]\n",
    "BUSINESS_PHONE: [value or N/A]\n",
    "BANK_NAME: [bank name from bank statements only or N/A]\n",
    "BSB_NUMBER: [6-digit BSB from bank statements only or N/A]\n",
    "BANK_ACCOUNT_NUMBER: [account number from bank statements only or N/A]\n",
    "ACCOUNT_HOLDER: [value or N/A]\n",
    "STATEMENT_PERIOD: [value or N/A]\n",
    "OPENING_BALANCE: [opening balance amount in dollars or N/A]\n",
    "CLOSING_BALANCE: [closing balance amount in dollars or N/A]\n",
    "DESCRIPTIONS: [list of transaction descriptions or N/A]\n",
    "\n",
    "FORMAT RULES:\n",
    "- Use exactly: KEY: value (colon and space)\n",
    "- NEVER use: **KEY:** or **KEY** or *KEY* or any formatting\n",
    "- Plain text only - NO markdown, NO bold, NO italic\n",
    "- Include ALL 25 keys even if value is N/A\n",
    "- Output ONLY these 25 lines, nothing else\n",
    "\n",
    "STOP after DESCRIPTIONS line. Do not add explanations or comments.\"\"\"\n",
    "\n",
    "print(\"üìã Advanced key-value extraction prompt configured for Llama Vision\")\n",
    "print(f\"üìÑ Prompt length: {len(extraction_prompt)} characters\")\n",
    "print(f\"üîç Extracting 25 standardized business document fields\")\n",
    "print(\"‚öôÔ∏è Configured for deterministic, structured output with markdown prevention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell 4: Llama Vision Key-Value Extraction Execution\n",
    "\n",
    "Purpose:\n",
    "- Execute structured field extraction using Llama Vision's multimodal capabilities\n",
    "- Process document with optimized generation parameters for structured output\n",
    "- Handle extraction with comprehensive error reporting and validation\n",
    "\n",
    "Llama Vision Processing Pipeline:\n",
    "1. Create multimodal message structure (image + text prompt)\n",
    "2. Apply chat template for proper formatting\n",
    "3. Process inputs through AutoProcessor\n",
    "4. Generate structured output with controlled parameters\n",
    "5. Validate and analyze extraction results\n",
    "\n",
    "Generation Configuration:\n",
    "- max_new_tokens=1000: Sufficient for 25 structured fields\n",
    "- do_sample=False: Deterministic for consistent extraction\n",
    "- temperature=None, top_p=None: Explicitly unset to avoid warnings\n",
    "- Proper device handling for GPU processing\n",
    "\n",
    "Advanced Error Handling:\n",
    "- Comprehensive exception catching with detailed diagnostics\n",
    "- Llama-specific error identification and troubleshooting\n",
    "- Memory management guidance for large vision models\n",
    "- Output validation and quality assessment\n",
    "\n",
    "Enhanced Output Processing:\n",
    "- Intelligent parsing to extract only structured response\n",
    "- Removes conversation history and prompt artifacts\n",
    "- Cleans markdown formatting for plain text output\n",
    "- Validates field structure and completeness\n",
    "\"\"\"\n",
    "\n",
    "# Create multimodal message structure for Llama Vision\n",
    "messageDataStructure = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": extraction_prompt,\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"ü§ñ Executing key-value extraction with Llama Vision...\")\n",
    "print(\"‚öôÔ∏è Using multimodal conversation format for optimal extraction\")\n",
    "\n",
    "try:\n",
    "    # Apply chat template for proper Llama formatting\n",
    "    textInput = processor.apply_chat_template(\n",
    "        messageDataStructure, add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    # Process inputs through AutoProcessor (handles both image and text)\n",
    "    inputs = processor(image, textInput, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    print(f\"üîß Input tensors prepared on device: {model.device}\")\n",
    "    \n",
    "    # Generate structured output with controlled parameters (no warnings)\n",
    "    output = model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens=1000,  # Adequate for 25 structured fields\n",
    "        do_sample=False,      # Deterministic for consistent extraction\n",
    "        temperature=None,     # Explicitly unset to avoid warning\n",
    "        top_p=None,          # Explicitly unset to avoid warning\n",
    "        pad_token_id=processor.tokenizer.eos_token_id  # Prevent warnings\n",
    "    )\n",
    "    \n",
    "    # Decode the response and extract only the assistant's response\n",
    "    generatedOutput = processor.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract only the assistant's response (after the last \"assistant\" token)\n",
    "    if \"assistant\" in generatedOutput:\n",
    "        # Split by assistant and take the last part (the actual response)\n",
    "        assistant_parts = generatedOutput.split(\"assistant\")\n",
    "        if len(assistant_parts) > 1:\n",
    "            generatedOutput = assistant_parts[-1].strip()\n",
    "    \n",
    "    # Additional cleaning: remove any remaining conversation artifacts\n",
    "    lines = generatedOutput.split('\\n')\n",
    "    cleaned_lines = []\n",
    "    in_response = False\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        # Look for the start of structured output (first field)\n",
    "        if line.startswith('DOCUMENT_TYPE:'):\n",
    "            in_response = True\n",
    "        # Skip user input or other artifacts\n",
    "        if line.startswith('user') or line.startswith('<image>') or line.startswith('Extract data'):\n",
    "            in_response = False\n",
    "            continue\n",
    "        # Collect response lines with proper field format\n",
    "        if in_response and ':' in line and not line.startswith('<'):\n",
    "            # Remove any markdown artifacts\n",
    "            clean_line = line.replace('**', '').replace('*', '')\n",
    "            cleaned_lines.append(clean_line)\n",
    "            # Stop after 25 fields as specified in prompt\n",
    "            if len(cleaned_lines) >= 25:\n",
    "                break\n",
    "    \n",
    "    # Use cleaned output if we found structured fields, otherwise use original\n",
    "    if cleaned_lines:\n",
    "        generatedOutput = '\\n'.join(cleaned_lines)\n",
    "    \n",
    "    print(\"‚úÖ Key-value extraction completed successfully!\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXTRACTED BUSINESS DOCUMENT FIELDS (LLAMA VISION):\")\n",
    "    print(\"=\"*60)\n",
    "    print(generatedOutput)\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Advanced extraction validation and analysis\n",
    "    lines = generatedOutput.split('\\n')\n",
    "    field_lines = [line for line in lines if ':' in line and not line.strip().startswith('<')]\n",
    "    \n",
    "    print(f\"\\nüìä Llama Vision Extraction Statistics:\")\n",
    "    print(f\"   ‚Ä¢ Total response lines: {len(lines)}\")\n",
    "    print(f\"   ‚Ä¢ Structured field lines: {len(field_lines)}\")\n",
    "    print(f\"   ‚Ä¢ Expected field count: 25\")\n",
    "    print(f\"   ‚Ä¢ Extraction completeness: {len(field_lines)/25*100:.1f}%\")\n",
    "    \n",
    "    # Quality assessment\n",
    "    if len(field_lines) == 25:\n",
    "        print(\"‚úÖ Perfect field extraction - all 25 fields captured\")\n",
    "    elif len(field_lines) > 20:\n",
    "        print(\"‚úÖ Near-complete extraction - minor fields may be missing\")\n",
    "    elif len(field_lines) > 0:\n",
    "        print(\"‚ö†Ô∏è Partial extraction - significant fields may be missing\")\n",
    "    else:\n",
    "        print(\"‚ùå No structured fields detected in response\")\n",
    "    \n",
    "    # Check for markdown artifacts (common with Llama models)\n",
    "    markdown_count = generatedOutput.count('**') + generatedOutput.count('*')\n",
    "    if markdown_count > 0:\n",
    "        print(f\"‚ö†Ô∏è Markdown artifacts detected: {markdown_count} instances\")\n",
    "        print(\"üí° Consider refining prompt to further suppress markdown formatting\")\n",
    "    else:\n",
    "        print(\"‚úÖ Clean plain text output - no markdown artifacts detected\")\n",
    "        \n",
    "except torch.cuda.OutOfMemoryError:\n",
    "    print(\"‚ùå GPU Memory Error: Insufficient VRAM for Llama Vision processing\")\n",
    "    print(\"üí° Solutions:\")\n",
    "    print(\"   ‚Ä¢ Reduce image resolution\")\n",
    "    print(\"   ‚Ä¢ Use CPU inference (slower but memory-efficient)\")\n",
    "    print(\"   ‚Ä¢ Clear GPU cache with torch.cuda.empty_cache()\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during Llama Vision extraction: {e}\")\n",
    "    print(f\"üîç Error type: {type(e).__name__}\")\n",
    "    print(\"\\nüìã Troubleshooting suggestions:\")\n",
    "    print(\"   ‚Ä¢ Verify document image quality and readability\")\n",
    "    print(\"   ‚Ä¢ Check model and processor compatibility\")\n",
    "    print(\"   ‚Ä¢ Ensure sufficient system resources\")\n",
    "    print(\"   ‚Ä¢ Validate multimodal input format\")\n",
    "    \n",
    "    import traceback\n",
    "    print(f\"\\nüîß Full error traceback:\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell 5: Advanced Results Management and Analysis Pipeline\n",
    "\n",
    "Purpose:\n",
    "- Save extracted key-value pairs with comprehensive analysis and reporting\n",
    "- Perform advanced quality validation and extraction confidence assessment\n",
    "- Generate detailed reports for workflow integration and process optimization\n",
    "\n",
    "Advanced File Operations:\n",
    "- Uses global output_dir for consistent file management\n",
    "- Descriptive filename with model identification\n",
    "- UTF-8 encoding with international character support\n",
    "- Atomic file operations to prevent data corruption\n",
    "\n",
    "Comprehensive Quality Analysis:\n",
    "- Field completeness assessment (target: 25 fields)\n",
    "- Content coverage analysis (non-N/A fields)\n",
    "- Markdown artifact detection and reporting\n",
    "- Data quality indicators for downstream processing\n",
    "- Extraction confidence scoring and validation\n",
    "\n",
    "Enhanced Error Handling:\n",
    "- Specific error types with targeted solutions\n",
    "- File system diagnostics and troubleshooting\n",
    "- Memory management guidance for large documents\n",
    "- Integration workflow validation\n",
    "\n",
    "Advanced Integration Features:\n",
    "- Structured output validation for database import\n",
    "- Quality metrics for automated processing workflows\n",
    "- Comparative analysis capabilities for model evaluation\n",
    "- Batch processing readiness indicators\n",
    "\"\"\"\n",
    "\n",
    "# Configure output path using global output_dir variable\n",
    "output_filename = \"llama_keyvalue_extraction.txt\"\n",
    "output_path = Path(output_dir) / output_filename\n",
    "\n",
    "print(f\"üíæ Saving Llama Vision extraction results to: {output_path}\")\n",
    "\n",
    "try:\n",
    "    # Ensure output directory exists with proper permissions\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Write extraction results with comprehensive metadata\n",
    "    with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "        # Add extraction metadata header\n",
    "        text_file.write(f\"# Llama Vision Key-Value Extraction Results\\n\")\n",
    "        text_file.write(f\"# Document: {document_image}\\n\")\n",
    "        text_file.write(f\"# Model: Llama-3.2-11B-Vision-Instruct\\n\")\n",
    "        text_file.write(f\"# Extraction Date: {Path().resolve()}\\n\")\n",
    "        text_file.write(\"# \" + \"=\"*50 + \"\\n\\n\")\n",
    "        text_file.write(generatedOutput)\n",
    "    \n",
    "    print(f\"‚úÖ Llama Vision extraction results saved successfully!\")\n",
    "    print(f\"üìÑ File location: {output_path}\")\n",
    "    print(f\"üìä File size: {output_path.stat().st_size} bytes\")\n",
    "    \n",
    "    # Advanced extraction analysis and reporting\n",
    "    lines = generatedOutput.split('\\n')\n",
    "    field_lines = [line for line in lines if ':' in line and not line.strip().startswith('<')]\n",
    "    \n",
    "    print(f\"\\nüìà Comprehensive Extraction Analysis:\")\n",
    "    print(f\"   ‚Ä¢ Document processed: {document_image}\")\n",
    "    print(f\"   ‚Ä¢ Model used: Llama-3.2-11B-Vision-Instruct\")\n",
    "    print(f\"   ‚Ä¢ Total response lines: {len(lines)}\")\n",
    "    print(f\"   ‚Ä¢ Structured field lines: {len(field_lines)}\")\n",
    "    print(f\"   ‚Ä¢ Field extraction rate: {len(field_lines)/25*100:.1f}%\")\n",
    "    \n",
    "    # Advanced content analysis\n",
    "    non_na_fields = [line for line in field_lines if not line.split(':', 1)[1].strip().upper() in ['N/A', 'NA']]\n",
    "    print(f\"   ‚Ä¢ Fields with content: {len(non_na_fields)}\")\n",
    "    print(f\"   ‚Ä¢ Content coverage: {len(non_na_fields)/25*100:.1f}%\")\n",
    "    \n",
    "    # Quality validation metrics\n",
    "    file_size = output_path.stat().st_size\n",
    "    if file_size > 500:\n",
    "        print(\"‚úÖ Output file validation: EXCELLENT (comprehensive content)\")\n",
    "    elif file_size > 200:\n",
    "        print(\"‚úÖ Output file validation: GOOD (sufficient content)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Output file validation: WARNING (minimal content detected)\")\n",
    "    \n",
    "    # Markdown artifact analysis\n",
    "    markdown_count = generatedOutput.count('**') + generatedOutput.count('*')\n",
    "    if markdown_count == 0:\n",
    "        print(\"‚úÖ Format validation: PERFECT (no markdown artifacts)\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Format validation: {markdown_count} markdown artifacts detected\")\n",
    "    \n",
    "    # Integration readiness assessment\n",
    "    if len(field_lines) >= 20 and markdown_count == 0:\n",
    "        print(\"üöÄ Integration Status: READY (high-quality structured output)\")\n",
    "    elif len(field_lines) >= 15:\n",
    "        print(\"‚öôÔ∏è Integration Status: USABLE (good quality with minor gaps)\")\n",
    "    else:\n",
    "        print(\"üîß Integration Status: NEEDS REVIEW (significant extraction issues)\")\n",
    "    \n",
    "    print(f\"\\nüîó Advanced Integration Features:\")\n",
    "    print(f\"   ‚Ä¢ Database-ready structured format: ‚úÖ\")\n",
    "    print(f\"   ‚Ä¢ API integration compatible: ‚úÖ\")\n",
    "    print(f\"   ‚Ä¢ Batch processing ready: ‚úÖ\")\n",
    "    print(f\"   ‚Ä¢ Quality metrics available: ‚úÖ\")\n",
    "    print(f\"üìÅ Output directory: {output_dir}\")\n",
    "    \n",
    "except NameError:\n",
    "    print(\"‚ùå Error: Extraction response not available\")\n",
    "    print(\"üí° Solution: Execute Cell 4 first to generate extraction results\")\n",
    "    print(\"üîÑ Then re-run this cell to save and analyze the results\")\n",
    "    print(\"üìã Ensure Llama Vision processing completed successfully\")\n",
    "    \n",
    "except PermissionError:\n",
    "    print(f\"‚ùå Permission Error: Cannot write to {output_path}\")\n",
    "    print(\"üí° Advanced Solutions:\")\n",
    "    print(\"   ‚Ä¢ Check directory write permissions\")\n",
    "    print(\"   ‚Ä¢ Verify output_dir path is accessible\")\n",
    "    print(\"   ‚Ä¢ Try running with appropriate user permissions\")\n",
    "    print(\"   ‚Ä¢ Consider alternative output directory\")\n",
    "    \n",
    "except OSError as e:\n",
    "    print(f\"‚ùå File System Error: {e}\")\n",
    "    print(\"üí° System Diagnostics:\")\n",
    "    print(\"   ‚Ä¢ Check available disk space\")\n",
    "    print(\"   ‚Ä¢ Verify path validity and accessibility\")\n",
    "    print(\"   ‚Ä¢ Ensure parent directories exist and are writable\")\n",
    "    print(\"   ‚Ä¢ Check file system permissions and quotas\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Unexpected error during file operations: {e}\")\n",
    "    print(f\"üîç Error type: {type(e).__name__}\")\n",
    "    print(\"üí° Advanced troubleshooting:\")\n",
    "    print(\"   ‚Ä¢ Check system resources and memory availability\")\n",
    "    print(\"   ‚Ä¢ Verify file path configuration and permissions\")\n",
    "    print(\"   ‚Ä¢ Review extraction output format and content\")\n",
    "    print(f\"üóÇÔ∏è Configured output directory: {output_dir}\")\n",
    "    print(f\"üìÑ Target filename: {output_filename}\")\n",
    "    \n",
    "    import traceback\n",
    "    print(f\"\\nüîß Detailed error analysis:\")\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (unified_vision_processor)",
   "language": "python",
   "name": "unified_vision_processor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
