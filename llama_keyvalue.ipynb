{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nCell 1: Environment Setup and Model Loading for Llama Vision Key-Value Extraction\n\nPurpose:\n- Import all required libraries for Llama-3.2-11B-Vision-Instruct model\n- Load the Llama Vision model optimized for structured key-value extraction\n- Initialize model with proper configuration for document analysis\n- Define global configuration variables for data paths\n\nKey Components:\n- torch.bfloat16: Memory-efficient 16-bit floating point for better performance\n- device_map=\"auto\": Automatic device mapping for optimal GPU utilization\n- AutoProcessor: Handles both text and image processing for Llama Vision\n- Optimized for multimodal document understanding\n\nGlobal Configuration:\n- data_dir: Centralized data directory path for all image operations\n- model_path: Local path to Llama-3.2-11B-Vision-Instruct model files\n- output_dir: Directory for saving extraction results\n\nSpecialized for Key-Value Extraction:\n- Optimized for structured document processing\n- Configured for business document analysis workflows\n- Supports multimodal conversation format required by Llama Vision\n\"\"\"\n\nfrom pathlib import Path\nimport torch\nfrom PIL import Image\nfrom transformers import AutoProcessor, MllamaForConditionalGeneration\n\n# Global configuration variables\ndata_dir = \"/home/jovyan/nfs_share/tod/huaifeng_data\"\nmodel_path = \"/home/jovyan/nfs_share/models/Llama-3.2-11B-Vision-Instruct\"\noutput_dir = \"/home/jovyan/nfs_share/tod/output\"\n\nprint(f\"üóÇÔ∏è  Data directory: {data_dir}\")\nprint(f\"üìÅ Output directory: {output_dir}\")\nprint(f\"üîß Loading Llama-3.2-11B-Vision-Instruct model for key-value extraction from: {model_path}\")\n\n# Load Llama Vision model with optimal configuration\nmodel = MllamaForConditionalGeneration.from_pretrained(\n    model_path,\n    torch_dtype=torch.bfloat16,  # Use bfloat16 for memory efficiency\n    device_map=\"auto\",           # Automatic device mapping for multi-GPU support\n)\n\n# Load processor for handling both text and image inputs\nprocessor = AutoProcessor.from_pretrained(model_path)\n\nprint(\"‚úÖ Llama Vision model and processor loaded successfully for key-value extraction\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nCell 2: Document Loading and Preprocessing for Llama Vision\n\nPurpose:\n- Load and preprocess business documents for key-value extraction\n- Handle various document formats with proper image processing\n- Prepare documents for Llama Vision's multimodal processing pipeline\n\nDocument Processing Features:\n- Supports various image formats (PNG, JPG, PDF conversions)\n- Handles different document orientations and sizes\n- Maintains image quality for optimal text recognition\n- Uses global data_dir for consistent path management\n\nLlama Vision Specific:\n- No complex tiling required (unlike InternVL3)\n- Direct image processing through AutoProcessor\n- Optimized for single-image document analysis\n- Maintains original aspect ratios for better text recognition\n\"\"\"\n\ndef load_document_image(image_path):\n    \"\"\"\n    Load document image with path flexibility\n    \n    Args:\n        image_path: Path to document file (relative to data_dir or absolute)\n    \n    Returns:\n        PIL.Image: Loaded document image ready for processing\n    \"\"\"\n    # Handle both relative and absolute paths\n    if not image_path.startswith('/'):\n        image_path = f\"{data_dir}/{image_path}\"\n    \n    return Image.open(image_path)\n\n# Load and analyze document using global data_dir\ndocument_image = \"synthetic_invoice_014.png\"  # Configurable document filename\nprint(f\"üìÑ Loading document from: {data_dir}/{document_image}\")\n\n# Load document image\nimage = load_document_image(document_image)\nprint(f\"üì∑ Document loaded successfully: {image.size}\")\nprint(f\"üìê Document aspect ratio: {image.size[0]/image.size[1]:.2f}\")\nprint(f\"üñºÔ∏è  Image format: {image.format}\")\nprint(f\"üé® Color mode: {image.mode}\")\nprint(\"üîç Document ready for Llama Vision key-value extraction\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nCell 3: Advanced Key-Value Extraction Prompt Configuration\n\nPurpose:\n- Define comprehensive prompt for extracting structured business document data\n- Configure extraction parameters for consistent, standardized output\n- Leverage Llama Vision's advanced reasoning capabilities for document analysis\n\nEnhanced Prompt Features:\n- 25 predefined fields covering comprehensive business document types\n- Advanced formatting constraints to prevent Llama's markdown tendencies\n- Explicit instructions optimized for Llama Vision's capabilities\n- Deterministic field ordering for automated downstream processing\n\nField Categories (Comprehensive Coverage):\n1. Document metadata (type, dates, references)\n2. Supplier/business information (name, address, contact details)\n3. Financial data (amounts, GST, totals, subtotals)\n4. Transaction details (quantities, prices, descriptions)\n5. Banking information (account numbers, BSB, balances)\n\nAdvanced Output Quality Controls:\n- Multiple examples of correct/incorrect formatting\n- Explicit markdown prevention (critical for Llama models)\n- Field count validation (exactly 25 lines)\n- Structured validation for downstream processing systems\n- Clear start/stop instructions to prevent conversation artifacts\n\"\"\"\n\n# Enhanced key-value extraction prompt optimized for Llama Vision\nextraction_prompt = \"\"\"Extract key-value data from this business document image.\n\nCRITICAL INSTRUCTIONS:\n- Output ONLY the structured data below\n- Do NOT include any conversation text\n- Do NOT repeat the user's request\n- Do NOT include <image> tokens\n- Start immediately with DOCUMENT_TYPE\n- Stop immediately after DESCRIPTIONS\n\nREQUIRED OUTPUT FORMAT - EXACTLY 25 LINES:\nDOCUMENT_TYPE: [value or N/A]\nSUPPLIER: [value or N/A]\nABN: [11-digit Australian Business Number or N/A]\nPAYER_NAME: [value or N/A]\nPAYER_ADDRESS: [value or N/A]\nPAYER_PHONE: [value or N/A]\nPAYER_EMAIL: [value or N/A]\nINVOICE_DATE: [value or N/A]\nDUE_DATE: [value or N/A]\nGST: [GST amount in dollars or N/A]\nTOTAL: [total amount in dollars or N/A]\nSUBTOTAL: [subtotal amount in dollars or N/A]\nSUPPLIER_WEBSITE: [value or N/A]\nQUANTITIES: [list of quantities or N/A]\nPRICES: [individual prices in dollars or N/A]\nBUSINESS_ADDRESS: [value or N/A]\nBUSINESS_PHONE: [value or N/A]\nBANK_NAME: [bank name from bank statements only or N/A]\nBSB_NUMBER: [6-digit BSB from bank statements only or N/A]\nBANK_ACCOUNT_NUMBER: [account number from bank statements only or N/A]\nACCOUNT_HOLDER: [value or N/A]\nSTATEMENT_PERIOD: [value or N/A]\nOPENING_BALANCE: [opening balance amount in dollars or N/A]\nCLOSING_BALANCE: [closing balance amount in dollars or N/A]\nDESCRIPTIONS: [list of transaction descriptions or N/A]\n\nFORMAT RULES:\n- Use exactly: KEY: value (colon and space)\n- NEVER use: **KEY:** or **KEY** or *KEY* or any formatting\n- Plain text only - NO markdown, NO bold, NO italic\n- Include ALL 25 keys even if value is N/A\n- Output ONLY these 25 lines, nothing else\n\nSTOP after DESCRIPTIONS line. Do not add explanations or comments.\"\"\"\n\nprint(\"üìã Advanced key-value extraction prompt configured for Llama Vision\")\nprint(f\"üìÑ Prompt length: {len(extraction_prompt)} characters\")\nprint(f\"üîç Extracting 25 standardized business document fields\")\nprint(\"‚öôÔ∏è Configured for deterministic, structured output with markdown prevention\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nCell 4: Llama Vision Key-Value Extraction Execution\n\nPurpose:\n- Execute structured field extraction using Llama Vision's multimodal capabilities\n- Process document with optimized generation parameters for structured output\n- Handle extraction with comprehensive error reporting and validation\n\nLlama Vision Processing Pipeline:\n1. Create multimodal message structure (image + text prompt)\n2. Apply chat template for proper formatting\n3. Process inputs through AutoProcessor\n4. Generate structured output with controlled parameters\n5. Validate and analyze extraction results\n\nGeneration Configuration:\n- max_new_tokens=1000: Sufficient for 25 structured fields\n- do_sample=False: Deterministic for consistent extraction\n- temperature=None, top_p=None: Explicitly unset to avoid warnings\n- Proper device handling for GPU processing\n\nAdvanced Error Handling:\n- Comprehensive exception catching with detailed diagnostics\n- Llama-specific error identification and troubleshooting\n- Memory management guidance for large vision models\n- Output validation and quality assessment\n\nEnhanced Output Processing:\n- Intelligent parsing to extract only structured response\n- Removes conversation history and prompt artifacts\n- Cleans markdown formatting for plain text output\n- Validates field structure and completeness\n\"\"\"\n\n# Create multimodal message structure for Llama Vision\nmessageDataStructure = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\"},\n            {\n                \"type\": \"text\",\n                \"text\": extraction_prompt,\n            },\n        ],\n    }\n]\n\nprint(\"ü§ñ Executing key-value extraction with Llama Vision...\")\nprint(\"‚öôÔ∏è Using multimodal conversation format for optimal extraction\")\n\ntry:\n    # Apply chat template for proper Llama formatting\n    textInput = processor.apply_chat_template(\n        messageDataStructure, add_generation_prompt=True\n    )\n    \n    # Process inputs through AutoProcessor (handles both image and text)\n    inputs = processor(image, textInput, return_tensors=\"pt\").to(model.device)\n    \n    print(f\"üîß Input tensors prepared on device: {model.device}\")\n    \n    # Generate structured output with controlled parameters (no warnings)\n    output = model.generate(\n        **inputs, \n        max_new_tokens=1000,  # Adequate for 25 structured fields\n        do_sample=False,      # Deterministic for consistent extraction\n        temperature=None,     # Explicitly unset to avoid warning\n        top_p=None,          # Explicitly unset to avoid warning\n        pad_token_id=processor.tokenizer.eos_token_id  # Prevent warnings\n    )\n    \n    # Decode the response and extract only the assistant's response\n    generatedOutput = processor.decode(output[0], skip_special_tokens=True)\n    \n    # Extract only the assistant's response (after the last \"assistant\" token)\n    if \"assistant\" in generatedOutput:\n        # Split by assistant and take the last part (the actual response)\n        assistant_parts = generatedOutput.split(\"assistant\")\n        if len(assistant_parts) > 1:\n            generatedOutput = assistant_parts[-1].strip()\n    \n    # Additional cleaning: remove any remaining conversation artifacts\n    lines = generatedOutput.split('\\n')\n    cleaned_lines = []\n    in_response = False\n    \n    for line in lines:\n        line = line.strip()\n        # Look for the start of structured output (first field)\n        if line.startswith('DOCUMENT_TYPE:'):\n            in_response = True\n        # Skip user input or other artifacts\n        if line.startswith('user') or line.startswith('<image>') or line.startswith('Extract data'):\n            in_response = False\n            continue\n        # Collect response lines with proper field format\n        if in_response and ':' in line and not line.startswith('<'):\n            # Remove any markdown artifacts\n            clean_line = line.replace('**', '').replace('*', '')\n            cleaned_lines.append(clean_line)\n            # Stop after 25 fields as specified in prompt\n            if len(cleaned_lines) >= 25:\n                break\n    \n    # Use cleaned output if we found structured fields, otherwise use original\n    if cleaned_lines:\n        generatedOutput = '\\n'.join(cleaned_lines)\n    \n    print(\"‚úÖ Key-value extraction completed successfully!\")\n    print(\"\\n\" + \"=\"*60)\n    print(\"EXTRACTED BUSINESS DOCUMENT FIELDS (LLAMA VISION):\")\n    print(\"=\"*60)\n    print(generatedOutput)\n    print(\"=\"*60)\n    \n    # Advanced extraction validation and analysis\n    lines = generatedOutput.split('\\n')\n    field_lines = [line for line in lines if ':' in line and not line.strip().startswith('<')]\n    \n    print(f\"\\nüìä Llama Vision Extraction Statistics:\")\n    print(f\"   ‚Ä¢ Total response lines: {len(lines)}\")\n    print(f\"   ‚Ä¢ Structured field lines: {len(field_lines)}\")\n    print(f\"   ‚Ä¢ Expected field count: 25\")\n    print(f\"   ‚Ä¢ Extraction completeness: {len(field_lines)/25*100:.1f}%\")\n    \n    # Quality assessment\n    if len(field_lines) == 25:\n        print(\"‚úÖ Perfect field extraction - all 25 fields captured\")\n    elif len(field_lines) > 20:\n        print(\"‚úÖ Near-complete extraction - minor fields may be missing\")\n    elif len(field_lines) > 0:\n        print(\"‚ö†Ô∏è Partial extraction - significant fields may be missing\")\n    else:\n        print(\"‚ùå No structured fields detected in response\")\n    \n    # Check for markdown artifacts (common with Llama models)\n    markdown_count = generatedOutput.count('**') + generatedOutput.count('*')\n    if markdown_count > 0:\n        print(f\"‚ö†Ô∏è Markdown artifacts detected: {markdown_count} instances\")\n        print(\"üí° Consider refining prompt to further suppress markdown formatting\")\n    else:\n        print(\"‚úÖ Clean plain text output - no markdown artifacts detected\")\n        \nexcept torch.cuda.OutOfMemoryError:\n    print(\"‚ùå GPU Memory Error: Insufficient VRAM for Llama Vision processing\")\n    print(\"üí° Solutions:\")\n    print(\"   ‚Ä¢ Reduce image resolution\")\n    print(\"   ‚Ä¢ Use CPU inference (slower but memory-efficient)\")\n    print(\"   ‚Ä¢ Clear GPU cache with torch.cuda.empty_cache()\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Error during Llama Vision extraction: {e}\")\n    print(f\"üîç Error type: {type(e).__name__}\")\n    print(\"\\nüìã Troubleshooting suggestions:\")\n    print(\"   ‚Ä¢ Verify document image quality and readability\")\n    print(\"   ‚Ä¢ Check model and processor compatibility\")\n    print(\"   ‚Ä¢ Ensure sufficient system resources\")\n    print(\"   ‚Ä¢ Validate multimodal input format\")\n    \n    import traceback\n    print(f\"\\nüîß Full error traceback:\")\n    traceback.print_exc()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nCell 5: Advanced Results Management and Analysis Pipeline\n\nPurpose:\n- Save extracted key-value pairs with comprehensive analysis and reporting\n- Perform advanced quality validation and extraction confidence assessment\n- Generate detailed reports for workflow integration and process optimization\n\nAdvanced File Operations:\n- Uses global output_dir for consistent file management\n- Descriptive filename with model identification\n- UTF-8 encoding with international character support\n- Atomic file operations to prevent data corruption\n\nComprehensive Quality Analysis:\n- Field completeness assessment (target: 25 fields)\n- Content coverage analysis (non-N/A fields)\n- Markdown artifact detection and reporting\n- Data quality indicators for downstream processing\n- Extraction confidence scoring and validation\n\nEnhanced Error Handling:\n- Specific error types with targeted solutions\n- File system diagnostics and troubleshooting\n- Memory management guidance for large documents\n- Integration workflow validation\n\nAdvanced Integration Features:\n- Structured output validation for database import\n- Quality metrics for automated processing workflows\n- Comparative analysis capabilities for model evaluation\n- Batch processing readiness indicators\n\"\"\"\n\n# Configure output path using global output_dir variable\noutput_filename = \"llama_keyvalue_extraction.txt\"\noutput_path = Path(output_dir) / output_filename\n\nprint(f\"üíæ Saving Llama Vision extraction results to: {output_path}\")\n\ntry:\n    # Ensure output directory exists with proper permissions\n    output_path.parent.mkdir(parents=True, exist_ok=True)\n    \n    # Write extraction results with comprehensive metadata\n    with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n        # Add extraction metadata header\n        text_file.write(f\"# Llama Vision Key-Value Extraction Results\\n\")\n        text_file.write(f\"# Document: {document_image}\\n\")\n        text_file.write(f\"# Model: Llama-3.2-11B-Vision-Instruct\\n\")\n        text_file.write(f\"# Extraction Date: {Path().resolve()}\\n\")\n        text_file.write(\"# \" + \"=\"*50 + \"\\n\\n\")\n        text_file.write(generatedOutput)\n    \n    print(f\"‚úÖ Llama Vision extraction results saved successfully!\")\n    print(f\"üìÑ File location: {output_path}\")\n    print(f\"üìä File size: {output_path.stat().st_size} bytes\")\n    \n    # Advanced extraction analysis and reporting\n    lines = generatedOutput.split('\\n')\n    field_lines = [line for line in lines if ':' in line and not line.strip().startswith('<')]\n    \n    print(f\"\\nüìà Comprehensive Extraction Analysis:\")\n    print(f\"   ‚Ä¢ Document processed: {document_image}\")\n    print(f\"   ‚Ä¢ Model used: Llama-3.2-11B-Vision-Instruct\")\n    print(f\"   ‚Ä¢ Total response lines: {len(lines)}\")\n    print(f\"   ‚Ä¢ Structured field lines: {len(field_lines)}\")\n    print(f\"   ‚Ä¢ Field extraction rate: {len(field_lines)/25*100:.1f}%\")\n    \n    # Advanced content analysis\n    non_na_fields = [line for line in field_lines if not line.split(':', 1)[1].strip().upper() in ['N/A', 'NA']]\n    print(f\"   ‚Ä¢ Fields with content: {len(non_na_fields)}\")\n    print(f\"   ‚Ä¢ Content coverage: {len(non_na_fields)/25*100:.1f}%\")\n    \n    # Quality validation metrics\n    file_size = output_path.stat().st_size\n    if file_size > 500:\n        print(\"‚úÖ Output file validation: EXCELLENT (comprehensive content)\")\n    elif file_size > 200:\n        print(\"‚úÖ Output file validation: GOOD (sufficient content)\")\n    else:\n        print(\"‚ö†Ô∏è Output file validation: WARNING (minimal content detected)\")\n    \n    # Markdown artifact analysis\n    markdown_count = generatedOutput.count('**') + generatedOutput.count('*')\n    if markdown_count == 0:\n        print(\"‚úÖ Format validation: PERFECT (no markdown artifacts)\")\n    else:\n        print(f\"‚ö†Ô∏è Format validation: {markdown_count} markdown artifacts detected\")\n    \n    # Integration readiness assessment\n    if len(field_lines) >= 20 and markdown_count == 0:\n        print(\"üöÄ Integration Status: READY (high-quality structured output)\")\n    elif len(field_lines) >= 15:\n        print(\"‚öôÔ∏è Integration Status: USABLE (good quality with minor gaps)\")\n    else:\n        print(\"üîß Integration Status: NEEDS REVIEW (significant extraction issues)\")\n    \n    print(f\"\\nüîó Advanced Integration Features:\")\n    print(f\"   ‚Ä¢ Database-ready structured format: ‚úÖ\")\n    print(f\"   ‚Ä¢ API integration compatible: ‚úÖ\")\n    print(f\"   ‚Ä¢ Batch processing ready: ‚úÖ\")\n    print(f\"   ‚Ä¢ Quality metrics available: ‚úÖ\")\n    print(f\"üìÅ Output directory: {output_dir}\")\n    \nexcept NameError:\n    print(\"‚ùå Error: Extraction response not available\")\n    print(\"üí° Solution: Execute Cell 4 first to generate extraction results\")\n    print(\"üîÑ Then re-run this cell to save and analyze the results\")\n    print(\"üìã Ensure Llama Vision processing completed successfully\")\n    \nexcept PermissionError:\n    print(f\"‚ùå Permission Error: Cannot write to {output_path}\")\n    print(\"üí° Advanced Solutions:\")\n    print(\"   ‚Ä¢ Check directory write permissions\")\n    print(\"   ‚Ä¢ Verify output_dir path is accessible\")\n    print(\"   ‚Ä¢ Try running with appropriate user permissions\")\n    print(\"   ‚Ä¢ Consider alternative output directory\")\n    \nexcept OSError as e:\n    print(f\"‚ùå File System Error: {e}\")\n    print(\"üí° System Diagnostics:\")\n    print(\"   ‚Ä¢ Check available disk space\")\n    print(\"   ‚Ä¢ Verify path validity and accessibility\")\n    print(\"   ‚Ä¢ Ensure parent directories exist and are writable\")\n    print(\"   ‚Ä¢ Check file system permissions and quotas\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Unexpected error during file operations: {e}\")\n    print(f\"üîç Error type: {type(e).__name__}\")\n    print(\"üí° Advanced troubleshooting:\")\n    print(\"   ‚Ä¢ Check system resources and memory availability\")\n    print(\"   ‚Ä¢ Verify file path configuration and permissions\")\n    print(\"   ‚Ä¢ Review extraction output format and content\")\n    print(f\"üóÇÔ∏è Configured output directory: {output_dir}\")\n    print(f\"üìÑ Target filename: {output_filename}\")\n    \n    import traceback\n    print(f\"\\nüîß Detailed error analysis:\")\n    traceback.print_exc()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}