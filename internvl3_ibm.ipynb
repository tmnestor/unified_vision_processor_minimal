{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbfe37e-efa8-4c44-8ab2-2ba5a59ef136",
   "metadata": {},
   "outputs": [],
   "source": "import math\nimport numpy as np\nimport torch\nimport torchvision.transforms as T\n# from decord import VideoReader, cpu  # Commented out since not needed for basic usage\nfrom PIL import Image\nfrom torchvision.transforms.functional import InterpolationMode\n\nimport torch\nfrom transformers import AutoConfig, AutoTokenizer, AutoModel\n\nprint(\"üîß Loading InternVL3-2B model...\")\nmodel_path = \"/home/jovyan/nfs_share/models/InternVL3-2B\"\nmodel = AutoModel.from_pretrained(\n    model_path,\n    torch_dtype=torch.bfloat16,\n    low_cpu_mem_usage=True,\n    use_flash_attn=False,\n    trust_remote_code=True).eval().cuda()\n\nprint(\"‚úÖ Model loaded successfully\")"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98631618-4648-46f2-af2b-7308eede6280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers_modules.OpenGVLab.InternVL3.tokenization_internvl import InternVLTokenizer\n",
    "# tokenizer = InternVLTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# # Look for the tokenizer class in the model directory\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "# # Add the model directory to Python path\n",
    "# model_path = \"/home/jovyan/nfs_share/models/huggingface/hub/InternVL3-1B\"\n",
    "# sys.path.append(model_path)\n",
    "\n",
    "# # Verify what's in the directory\n",
    "# print(os.listdir(model_path))\n",
    "\n",
    "# # Then try importing the tokenizer from there\n",
    "# from tokenization_internvl import InternVLTokenizer\n",
    "# tokenizer = InternVLTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b2a5af-b850-4178-bdc4-6e9762acaf77",
   "metadata": {},
   "outputs": [],
   "source": "# Fixed tokenizer loading for InternVL3-2B\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\n    model_path, \n    trust_remote_code=True, \n    use_fast=False  # Important for InternVL3\n)\nprint(\"‚úÖ Tokenizer loaded successfully\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b8847-e1c7-4a1c-b7f6-ad7a1b9d468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb034f-5400-430a-ad2e-2f91b99d9965",
   "metadata": {},
   "source": [
    "## [Quick Start](https://huggingface.co/OpenGVLab/InternVL3-1B#quick-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbef2766-fbeb-4fcd-ac57-70bfa01441df",
   "metadata": {},
   "outputs": [],
   "source": "# Simple image processing (from official InternVL3 docs)\ndef load_image(image, input_size=448):\n    \"\"\"Simple image preprocessing following official InternVL3 docs\"\"\"\n    transform = T.Compose([\n        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n        T.Resize((input_size, input_size)),\n        T.ToTensor(),\n        T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n    ])\n    return transform(image).unsqueeze(0).to(torch.bfloat16).cuda()\n\n# Load and process image\nimageName = \"/home/jovyan/nfs_share/tod/datasets/synthetic_invoice_014.png\"\nimage = Image.open(imageName)\nprint(f\"üì∑ Image loaded: {image.size}\")\n\nprint(\"üñºÔ∏è  Processing image...\")\npixel_values = load_image(image)\nprint(f\"‚úÖ Image processed: {pixel_values.shape}\")\n\n# Generation config\ngeneration_config = dict(max_new_tokens=1024, do_sample=True)\n\n# Test simple image conversation\nquestion = '<image>\\nPlease describe the image shortly.'\nprint(f\"‚ùì Question: {question}\")\n\nprint(\"ü§ñ Generating response...\")\ntry:\n    response = model.chat(tokenizer, pixel_values, question, generation_config)\n    print(\"‚úÖ Response generated successfully!\")\n    print(\"\\n\" + \"=\"*50)\n    print(\"RESPONSE:\")\n    print(response)\n    print(\"=\"*50)\n    \nexcept Exception as e:\n    print(f\"‚ùå Error during inference: {e}\")\n    print(f\"Error type: {type(e).__name__}\")\n    import traceback\n    traceback.print_exc()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a447a1-93d6-4f6d-8a26-643dd9fd4ce0",
   "metadata": {},
   "outputs": [],
   "source": "# Save response to file (optional)\nfrom pathlib import Path\n\ntry:\n    output_path = Path(\"/home/jovyan/nfs_share/tod/output/internvl3_ibm_output.txt\")\n    output_path.parent.mkdir(parents=True, exist_ok=True)\n    \n    with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n        text_file.write(response)\n    \n    print(f\"‚úÖ Response saved to: {output_path}\")\n    print(f\"üìÑ File size: {output_path.stat().st_size} bytes\")\n    \nexcept NameError:\n    print(\"‚ùå Error: 'response' variable not defined.\")\n    print(\"üí° Please run the previous cell first to generate the response.\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Error saving file: {e}\")\n    print(f\"üí° Check if directory exists: {output_path.parent}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (unified_vision_processor)",
   "language": "python",
   "name": "unified_vision_processor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}