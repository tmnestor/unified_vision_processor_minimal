# Model Comparison Configuration
# Contains all settings for model comparison: fields, prompts, success criteria, and generation parameters



# Success criteria and quality thresholds
min_fields_for_success: 1  # Document is successful if it extracts at least 1 fields

# Quality rating thresholds for field extraction (realistic for business documents)
quality_thresholds:
  excellent: 12    # 12+ fields = Excellent (nearly half of possible fields)
  good: 8          # 8-11 fields = Good (solid extraction)
  fair: 5          # 5-7 fields = Fair (basic extraction)
  poor: 0          # <5 fields = Poor

# Processing speed rating thresholds (seconds per document - realistic for H200/V100)
speed_thresholds:
  very_fast: 15.0  # <15s = Very Fast (optimized)
  fast: 25.0       # 15-25s = Fast (good performance)
  moderate: 40.0   # 25-40s = Moderate (acceptable)
                   # >40s = Slow (needs optimization)

# Memory and hardware configuration
memory_config:
  v100_limit_gb: 16.0      # V100 GPU memory limit
  safety_margin: 0.85      # Use 85% of available memory for safety
  
# Image processing configuration  
image_processing:
  max_image_size: 1024     # Maximum image dimension for resizing
  timeout_seconds: 10      # Processing timeout per image

# Note: Fields are defined in the prompts section below
# The system parses expected fields dynamically from the prompt text

# CLI defaults
defaults:
  datasets_path: "datasets"  # Default datasets directory
  max_tokens: 700  # Ensure all 26 key-value pairs are generated while limiting explanations
  quantization: true  # Enable 8-bit quantization for V100
  output_dir: "results"  # Default output directory
  models: "llama,internvl"  # Default models to compare
  trust_remote_code: true  # Enable custom model architectures (InternVL requires this)
  debug_mode: false  # Control debug output in comparison runner
  
# Model-specific configurations
model_config:
  llama:
    max_new_tokens_limit: 2024  # Exact multiple of model architecture
    confidence_score: 0.85      # Default confidence for Llama responses
  internvl:
    max_new_tokens_limit: 2024  # Ensure consistent limits across models
    confidence_score: 0.95      # Default confidence for InternVL responses

# Post-processing configuration
post_processing:
  enabled: true               # Keep post-processing enabled (some responses still need markdown cleaning)
  smart_mode: true            # Use smart detection: skip processing for clean responses, process messy ones
  force_parsing: false        # Force field parsing even with clean output
  
# Repetition control configuration  
repetition_control:
  enabled: true               # Enable repetition detection and cleanup
  word_threshold: 0.15        # 15% word repetition threshold
  phrase_threshold: 2         # 2 phrase repetitions trigger cleaning
  fallback_max_tokens: 1000   # Fallback token limit for repetition control

# Device configuration for V100 production deployment
device_config:
  # GPU allocation strategy
  gpu_strategy: "single_gpu"  # Options: single_gpu, multi_gpu, auto
  target_gpu: 0  # Which GPU to use for single_gpu mode
  
  # V100 production constraints (16GB VRAM, 64GB RAM)
  v100_mode: true  # Enable V100 production optimizations
  memory_limit_gb: 16  # GPU memory limit for V100
  
  # Device mapping configurations per model
  device_maps:
    llama:
      strategy: "single_gpu"  # Force everything on one GPU
      device_map: {"": 0}  # PyTorch device_map format
      quantization_compatible: true
      
    internvl:
      strategy: "single_gpu"  # Force everything on one GPU  
      device_map: {"": 0}  # PyTorch device_map format
      quantization_compatible: true
      
  # Alternative configurations (commented for reference)
  # multi_gpu_example:
  #   llama:
  #     strategy: "multi_gpu"
  #     device_map: "auto"  # Let PyTorch decide
  #   internvl:
  #     strategy: "split_layers"
  #     device_map:
  #       "vision_model": 0
  #       "language_model.model.layers": 0
  #       "language_model.model.layers.1": 1
  
# Model paths
model_paths:
  llama: "/home/jovyan/nfs_share/models/Llama-3.2-11B-Vision-Instruct"
  internvl: "/home/jovyan/nfs_share/models/InternVL3-8B"


# System prompts for controlling model behavior
system_prompts:
  llama: |
    You are a helpful assistant. When responding, do not use asterisks (*) for emphasis or bold formatting. Use plain text only without any markdown formatting symbols. Do not use **bold** formatting, _italics_, or any other special characters for text formatting. Present all text in a simple, unformatted manner with just KEY: value pairs.
    
    CRITICAL: Output EXACTLY 26 lines in the specified order. Do NOT add extra fields you find in the document. Do NOT include fields like "Balance", "Credit", "Debit", "Date", "Description" or any other fields not in the required list. Only output the 26 fields specified in the prompt, even if you see other data in the document.
  
  internvl: |
    Extract data accurately from business documents.

# Main extraction prompt - shared by all models
extraction_prompt: |
  Extract data from this business document. Output ALL fields below with their exact keys. Use "N/A" if field is not visible or not present.

  REQUIRED OUTPUT FORMAT (output ALL lines exactly as shown):
  DOCUMENT_TYPE: [value or N/A]
  SUPPLIER: [value or N/A]
  ABN: [11-digit Australian Business Number or N/A]
  PAYER_NAME: [value or N/A]
  PAYER_ADDRESS: [value or N/A]
  PAYER_PHONE: [value or N/A]
  PAYER_EMAIL: [value or N/A]
  INVOICE_DATE: [value or N/A]
  DUE_DATE: [value or N/A]
  GST: [GST amount in dollars or N/A]
  TOTAL: [total amount in dollars or N/A]
  SUBTOTAL: [subtotal amount in dollars or N/A]
  SUPPLIER_WEBSITE: [value or N/A]
  ITEMS: [value or N/A]
  QUANTITIES: [value or N/A]
  PRICES: [individual prices in dollars or N/A]
  BUSINESS_ADDRESS: [value or N/A]
  BUSINESS_PHONE: [value or N/A]
  BANK_NAME: [bank name from bank statements only or N/A]
  BSB_NUMBER: [6-digit BSB from bank statements only or N/A]
  BANK_ACCOUNT_NUMBER: [account number from bank statements only or N/A]
  ACCOUNT_HOLDER: [value or N/A]
  STATEMENT_PERIOD: [value or N/A]
  OPENING_BALANCE: [opening balance amount in dollars or N/A]
  CLOSING_BALANCE: [closing balance amount in dollars or N/A]
  TRANSACTIONS: [list of transactions with dates and amounts or N/A]

  CRITICAL: Output in PLAIN TEXT format only. Do NOT use markdown formatting.
  
  CORRECT format: DOCUMENT_TYPE: TAX INVOICE
  WRONG format: **DOCUMENT_TYPE:** TAX INVOICE
  WRONG format: **DOCUMENT_TYPE: TAX INVOICE**
  WRONG format: DOCUMENT_TYPE: **TAX INVOICE**
  
  Use exactly: KEY: value (with colon and space)
  Never use: **KEY:** or **KEY** or any asterisks
  Never use bold, italic, or any markdown formatting
  
  ABSOLUTELY CRITICAL: Output EXACTLY 26 lines using ONLY the keys listed above. 
  Do NOT add extra fields like "Balance", "Credit", "Debit", "Date", "Description".
  Do NOT include ANY fields not in the required list above.
  Include ALL 26 keys listed above even if value is N/A.
  STOP after exactly 26 lines.

# Note: Both models use the same extraction_prompt defined above
# This ensures consistent field extraction across all models