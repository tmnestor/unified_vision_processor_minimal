{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nCell 1: Environment Setup and Model Loading for Batch Key-Value Extraction\n\nPurpose:\n- Import all required libraries for InternVL3-2B vision-language model and batch processing\n- Load the InternVL3-2B model with compatibility fixes for stable inference\n- Initialize model with proper dtype and settings for batch document processing\n- Define global configuration variables for data paths and CSV output\n\nKey Components (Compatibility Optimized):\n- torch.bfloat16: Recommended precision for optimal performance\n- use_flash_attn=False: Disabled for compatibility (fixes dtype mismatch errors)\n- low_cpu_mem_usage=True: Optimize CPU memory during loading\n- trust_remote_code=True: Allow loading custom model code from HuggingFace\n- .eval().cuda(): Set model to evaluation mode and move to GPU\n\nGlobal Configuration:\n- data_dir: Centralized data directory path for all image operations\n- model_path: Local path to InternVL3-2B model files\n- output_dir: Directory for saving extraction results and CSV files\n\nBatch Processing Libraries:\n- pandas: For CSV generation and data management\n- pathlib: For robust file path handling\n- glob: For image file discovery\n\"\"\"\n\nfrom pathlib import Path\nimport torch\nfrom PIL import Image\nfrom transformers import AutoModel, AutoTokenizer\nimport torchvision.transforms as T\nimport pandas as pd\nimport glob\nfrom datetime import datetime\n\n# Check transformers version (should be >=4.37.2)\nimport transformers\nprint(f\"üîç Transformers version: {transformers.__version__}\")\n\n# Global configuration variables\ndata_dir = \"/home/jovyan/nfs_share/tod/huaifeng_data\"\nmodel_path = \"/home/jovyan/nfs_share/models/InternVL3-2B\" \noutput_dir = \"/home/jovyan/nfs_share/tod/output\"\n\nprint(f\"üóÇÔ∏è  Data directory: {data_dir}\")\nprint(f\"üìÅ Output directory: {output_dir}\")\nprint(f\"üîß Loading InternVL3-2B model with compatibility fixes from: {model_path}\")\n\n# Load model with compatibility settings (use_flash_attn=False to fix dtype errors)\nmodel = AutoModel.from_pretrained(\n    model_path,\n    torch_dtype=torch.bfloat16,   # Official recommendation: use bfloat16\n    low_cpu_mem_usage=True,       # Optimize CPU memory during loading\n    use_flash_attn=False,         # FIXED: Disabled for compatibility (prevents dtype mismatch)\n    trust_remote_code=True        # Allow custom model code execution\n).eval().cuda()                   # Set to evaluation mode and move to GPU\n\n# Load tokenizer with official settings\ntokenizer = AutoTokenizer.from_pretrained(\n    model_path, \n    trust_remote_code=True,  # Allow custom tokenizer code\n    use_fast=False          # Use slower but more reliable tokenizer for structured tasks\n)\n\nprint(\"‚úÖ Model and tokenizer loaded successfully with compatibility fixes\")\nprint(\"üìä Batch processing libraries imported: pandas, glob, datetime\")\nprint(\"üöÄ Ready for batch key-value extraction across all images\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nCell 2: Official InternVL3 Dynamic Image Processing Pipeline\n\nPurpose:\n- Implement official InternVL3 dynamic image preprocessing following documentation\n- Support dynamic tiling with proper dtype consistency\n- Handle document formats with optimal preprocessing for text extraction\n\nOfficial Dynamic Preprocessing Features (from InternVL3 docs):\n1. build_transform(): Official transformation pipeline with proper normalization\n2. find_closest_aspect_ratio(): Aspect ratio optimization for multiple tiles\n3. dynamic_preprocess(): Official dynamic tiling algorithm (1-12 tiles max)\n4. load_image(): Complete preprocessing with proper dtype handling\n\nKey Requirements from Documentation:\n- Proper dtype consistency (bfloat16 throughout pipeline)\n- ImageNet normalization constants\n- BICUBIC interpolation for quality\n- Dynamic tiling with thumbnail support\n- Memory-safe processing with configurable max_num\n\"\"\"\n\nimport math\n\n# Official ImageNet normalization constants\nIMAGENET_MEAN = (0.485, 0.456, 0.406)\nIMAGENET_STD = (0.229, 0.224, 0.225)\n\ndef build_transform(input_size):\n    \"\"\"\n    Official InternVL3 image transformation pipeline\n    \n    Args:\n        input_size: Target size for image resizing (default 448)\n    \n    Returns:\n        torchvision.transforms.Compose: Official transformation pipeline\n    \"\"\"\n    MEAN, STD = IMAGENET_MEAN, IMAGENET_STD\n    transform = T.Compose([\n        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n        T.Resize((input_size, input_size), interpolation=T.InterpolationMode.BICUBIC),\n        T.ToTensor(),\n        T.Normalize(mean=MEAN, std=STD)\n    ])\n    return transform\n\ndef find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n    \"\"\"\n    Official InternVL3 aspect ratio optimization algorithm\n    \"\"\"\n    best_ratio_diff = float('inf')\n    best_ratio = (1, 1)\n    area = width * height\n    for ratio in target_ratios:\n        target_aspect_ratio = ratio[0] / ratio[1]\n        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n        if ratio_diff < best_ratio_diff:\n            best_ratio_diff = ratio_diff\n            best_ratio = ratio\n        elif ratio_diff == best_ratio_diff:\n            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n                best_ratio = ratio\n    return best_ratio\n\ndef dynamic_preprocess(image, min_num=1, max_num=12, image_size=448, use_thumbnail=False):\n    \"\"\"\n    Official InternVL3 dynamic preprocessing algorithm\n    \"\"\"\n    orig_width, orig_height = image.size\n    aspect_ratio = orig_width / orig_height\n\n    # Calculate the existing image aspect ratio\n    target_ratios = set(\n        (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if\n        i * j <= max_num and i * j >= min_num)\n    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n\n    # Find the closest aspect ratio to the target\n    target_aspect_ratio = find_closest_aspect_ratio(\n        aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n\n    # Calculate the target width and height\n    target_width = image_size * target_aspect_ratio[0]\n    target_height = image_size * target_aspect_ratio[1]\n    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n\n    # Resize the image\n    resized_img = image.resize((target_width, target_height))\n    processed_images = []\n    for i in range(blocks):\n        box = (\n            (i % (target_width // image_size)) * image_size,\n            (i // (target_width // image_size)) * image_size,\n            ((i % (target_width // image_size)) + 1) * image_size,\n            ((i // (target_width // image_size)) + 1) * image_size\n        )\n        # Split the image\n        split_img = resized_img.crop(box)\n        processed_images.append(split_img)\n    assert len(processed_images) == blocks\n    if use_thumbnail and len(processed_images) != 1:\n        thumbnail_img = image.resize((image_size, image_size))\n        processed_images.append(thumbnail_img)\n    return processed_images\n\ndef load_image(image_file, input_size=448, max_num=12):\n    \"\"\"\n    Official InternVL3 image loading with proper dtype handling\n    \n    Args:\n        image_file: Path to image file (relative to data_dir or absolute)\n        input_size: Target size for each tile\n        max_num: Maximum number of tiles to generate (1-12 as per docs)\n    \n    Returns:\n        torch.Tensor: Properly processed image tensor with correct dtype (bfloat16)\n    \"\"\"\n    # Handle both relative and absolute paths\n    if not image_file.startswith('/'):\n        image_file = f\"{data_dir}/{image_file}\"\n    \n    image = Image.open(image_file).convert('RGB')\n    transform = build_transform(input_size=input_size)\n    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n    pixel_values = [transform(image) for image in images]\n    pixel_values = torch.stack(pixel_values)\n    \n    # CRITICAL: Ensure proper dtype for InternVL3 (must match model's bfloat16)\n    return pixel_values.to(torch.bfloat16).cuda()\n\n# Load and process document following official guidelines\ndocument_image = \"image2.png\"  # Configurable document filename\nprint(f\"üìÑ Loading document from: {data_dir}/{document_image}\")\n\n# Load original image for analysis\nimage_path = f\"{data_dir}/{document_image}\"\noriginal_image = Image.open(image_path)\nprint(f\"üì∑ Original document size: {original_image.size}\")\nprint(f\"üìê Document aspect ratio: {original_image.size[0]/original_image.size[1]:.2f}\")\n\n# Process with official dynamic preprocessing\nprint(\"üñºÔ∏è  Processing with official InternVL3 dynamic preprocessing...\")\npixel_values = load_image(document_image, max_num=12)\nprint(f\"‚úÖ Document processed into {pixel_values.shape[0]} tiles: {pixel_values.shape}\")\nprint(f\"üîç Tensor dtype: {pixel_values.dtype} (should be torch.bfloat16)\")\nprint(\"üìã Ready for InternVL3 key-value extraction\")"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Structured key-value extraction prompt configured\n",
      "üìÑ Prompt length: 1912 characters\n",
      "üîç Extracting 25 standardized business document fields\n",
      "‚öôÔ∏è Configured for deterministic, structured output\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cell 3: Structured Key-Value Extraction Prompt Configuration\n",
    "\n",
    "Purpose:\n",
    "- Define comprehensive prompt for extracting structured business document data\n",
    "- Configure extraction parameters for consistent, standardized output\n",
    "- Specify exact output format requirements for downstream processing\n",
    "\n",
    "Extraction Specifications:\n",
    "- 25 predefined fields covering common business document types\n",
    "- Supports invoices, receipts, bank statements, and tax documents\n",
    "- Handles missing fields gracefully with \"N/A\" placeholders\n",
    "- Enforces plain text output without markdown formatting\n",
    "- Ensures deterministic field ordering for automated processing\n",
    "\n",
    "Field Categories:\n",
    "1. Document metadata (type, dates)\n",
    "2. Supplier/business information (name, address, contact)\n",
    "3. Financial data (amounts, GST, totals)\n",
    "4. Transaction details (quantities, prices, descriptions)\n",
    "5. Banking information (account numbers, BSB, balances)\n",
    "\n",
    "Output Quality Controls:\n",
    "- Explicit formatting rules to prevent markdown artifacts\n",
    "- Character limits and validation requirements\n",
    "- Structured field validation for downstream systems\n",
    "\"\"\"\n",
    "\n",
    "# Comprehensive key-value extraction prompt optimized for business documents\n",
    "extraction_prompt = \"\"\"Extract data from this business document. \n",
    "Output ALL fields below with their exact keys. \n",
    "Use \"N/A\" if field is not visible or not present.\n",
    "\n",
    "REQUIRED OUTPUT FORMAT (output ALL lines exactly as shown):\n",
    "DOCUMENT_TYPE: [value or N/A]\n",
    "SUPPLIER: [value or N/A]\n",
    "ABN: [11-digit Australian Business Number or N/A]\n",
    "PAYER_NAME: [value or N/A]\n",
    "PAYER_ADDRESS: [value or N/A]\n",
    "PAYER_PHONE: [value or N/A]\n",
    "PAYER_EMAIL: [value or N/A]\n",
    "INVOICE_DATE: [value or N/A]\n",
    "DUE_DATE: [value or N/A]\n",
    "GST: [GST amount in dollars or N/A]\n",
    "TOTAL: [total amount in dollars or N/A]\n",
    "SUBTOTAL: [subtotal amount in dollars or N/A]\n",
    "SUPPLIER_WEBSITE: [value or N/A]\n",
    "QUANTITIES: [list of quantities or N/A]\n",
    "PRICES: [individual prices in dollars or N/A]\n",
    "BUSINESS_ADDRESS: [value or N/A]\n",
    "BUSINESS_PHONE: [value or N/A]\n",
    "BANK_NAME: [bank name from bank statements only or N/A]\n",
    "BSB_NUMBER: [6-digit BSB from bank statements only or N/A]\n",
    "BANK_ACCOUNT_NUMBER: [account number from bank statements only or N/A]\n",
    "ACCOUNT_HOLDER: [value or N/A]\n",
    "STATEMENT_PERIOD: [value or N/A]\n",
    "OPENING_BALANCE: [opening balance amount in dollars or N/A]\n",
    "CLOSING_BALANCE: [closing balance amount in dollars or N/A]\n",
    "DESCRIPTIONS: [list of transaction descriptions or N/A]\n",
    "\n",
    "CRITICAL: Output in PLAIN TEXT format only. Do NOT use markdown formatting.\n",
    "\n",
    "CORRECT format: DOCUMENT_TYPE: TAX INVOICE\n",
    "WRONG format: **DOCUMENT_TYPE:** TAX INVOICE\n",
    "WRONG format: **DOCUMENT_TYPE: TAX INVOICE**\n",
    "WRONG format: DOCUMENT_TYPE: **TAX INVOICE**\n",
    "\n",
    "Use exactly: KEY: value (with colon and space)\n",
    "Never use: **KEY:** or **KEY** or any asterisks\n",
    "Never use bold, italic, or any markdown formatting\n",
    "\n",
    "ABSOLUTELY CRITICAL: Output EXACTLY 25 lines using ONLY the keys listed above. \n",
    "Do NOT add extra fields like \\\"Balance\\\", \\\"Credit\\\", \\\"Debit\\\", \\\"Date\\\", \\\"Description\\\".\n",
    "Do NOT include ANY fields not in the required list above.\n",
    "Include ALL 25 keys listed above even if value is N/A.\n",
    "STOP after exactly 25 lines.\"\"\"\n",
    "\n",
    "# Format prompt for InternVL3 with proper image token\n",
    "question = f'<image>\\n{extraction_prompt}'\n",
    "\n",
    "print(\"üìã Structured key-value extraction prompt configured\")\n",
    "print(f\"üìÑ Prompt length: {len(extraction_prompt)} characters\")\n",
    "print(f\"üîç Extracting 25 standardized business document fields\")\n",
    "print(\"‚öôÔ∏è Configured for deterministic, structured output\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "\"\"\"\nCell 4: Enhanced Batch Key-Value Extraction with Corrected Success Metrics\n\nPurpose:\n- Execute batch processing across all images in data_dir with accurate success tracking\n- Generate comprehensive CSV output with corrected extraction metrics\n- Provide detailed statistics distinguishing response completeness from content coverage\n\nEnhanced Execution Pipeline:\n1. Discover all image files in the configured data directory\n2. Process each image through InternVL3 extraction pipeline with success tracking\n3. Parse and structure extraction results with metadata about model performance\n4. Create pandas DataFrame with proper column ordering and success analysis\n5. Export results to CSV with comprehensive metadata and corrected statistics\n\nCorrected Success Metrics:\n- Response Completeness: How many field keys the model actually returned\n- Content Coverage: How many returned keys have non-N/A values\n- True Success Rate: Based on model returning keys, not field content\n\nOutput Format:\n- CSV Structure: image_name + 25 alphabetically ordered field columns\n- Metadata tracking: Response completeness and content coverage per image\n- File Location: {output_dir}/internvl3_batch_extraction.csv\n- Enhanced statistics: Accurate model performance assessment\n\"\"\"\n\n# Generation configuration optimized for structured output\ngeneration_config = dict(\n    max_new_tokens=1000,                    # Adequate tokens for 25 structured fields\n    do_sample=False,                        # Deterministic for consistent field extraction\n    pad_token_id=tokenizer.eos_token_id     # Prevent pad_token_id warnings\n)\n\nprint(\"üîç Discovering images in data directory...\")\nimage_files = discover_images(data_dir)\n\nif not image_files:\n    print(f\"‚ùå No image files found in {data_dir}\")\n    print(\"üí° Supported formats: PNG, JPG, JPEG (case insensitive)\")\nelse:\n    print(f\"‚úÖ Found {len(image_files)} image files to process\")\n    \n    # Show sample of files that will be processed\n    print(\"\\nüìã Sample of files to be processed:\")\n    for i, file_path in enumerate(image_files[:5]):\n        print(f\"   {i+1}. {Path(file_path).name}\")\n    if len(image_files) > 5:\n        print(f\"   ... and {len(image_files) - 5} more files\")\n    \n    print(f\"\\nüöÄ Starting enhanced batch key-value extraction with corrected metrics...\")\n    start_time = datetime.now()\n    \n    try:\n        # Process all images through enhanced extraction pipeline\n        extraction_results, batch_statistics = process_image_batch(image_files)\n        \n        # Create structured DataFrame with proper column ordering and metadata\n        print(\"\\nüìä Creating structured DataFrame with success metrics...\")\n        df, metadata_df = create_extraction_dataframe(extraction_results)\n        \n        print(f\"‚úÖ Successfully created DataFrame with {len(df)} rows and {len(df.columns)} columns\")\n        print(f\"üìã Column structure: image_name + {len(EXTRACTION_FIELDS)} alphabetically ordered fields\")\n        \n        # Generate CSV output\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        csv_filename = \"internvl3_batch_extraction.csv\"\n        csv_filename_timestamped = f\"internvl3_batch_extraction_{timestamp}.csv\"\n        \n        csv_path = Path(output_dir) / csv_filename\n        csv_path_timestamped = Path(output_dir) / csv_filename_timestamped\n        \n        # Ensure output directory exists\n        csv_path.parent.mkdir(parents=True, exist_ok=True)\n        \n        # Save main CSV file (without metadata columns)\n        df.to_csv(csv_path, index=False, encoding='utf-8')\n        print(f\"üíæ Main CSV saved: {csv_path}\")\n        \n        # Save timestamped backup\n        df.to_csv(csv_path_timestamped, index=False, encoding='utf-8')\n        print(f\"üìÑ Backup CSV saved: {csv_path_timestamped}\")\n        \n        # Save metadata for analysis (optional detailed file)\n        if not metadata_df.empty:\n            metadata_path = Path(output_dir) / f\"internvl3_extraction_metadata_{timestamp}.csv\"\n            metadata_df.to_csv(metadata_path, index=False, encoding='utf-8')\n            print(f\"üìà Metadata saved: {metadata_path}\")\n        \n        # Enhanced processing statistics with corrected metrics\n        end_time = datetime.now()\n        processing_duration = end_time - start_time\n        \n        print(f\"\\nüìà Enhanced Batch Processing Summary:\")\n        print(f\"   ‚Ä¢ Total images processed: {batch_statistics['total_images']}\")\n        print(f\"   ‚Ä¢ Successful model responses: {batch_statistics['successful_responses']}\")\n        print(f\"   ‚Ä¢ Processing errors: {batch_statistics['processing_errors']}\")\n        print(f\"   ‚Ä¢ Processing duration: {processing_duration}\")\n        print(f\"   ‚Ä¢ Average time per image: {processing_duration.total_seconds() / len(extraction_results):.2f} seconds\")\n        \n        # Corrected success rate analysis\n        total_possible_fields = len(extraction_results) * len(EXTRACTION_FIELDS)\n        overall_response_rate = (batch_statistics['total_fields_returned'] / total_possible_fields) * 100\n        overall_content_rate = (batch_statistics['total_fields_with_content'] / batch_statistics['total_fields_returned']) * 100 if batch_statistics['total_fields_returned'] > 0 else 0\n        \n        print(f\"\\nüéØ Corrected Extraction Performance Metrics:\")\n        print(f\"   ‚Ä¢ Total possible field extractions: {total_possible_fields:,}\")\n        print(f\"   ‚Ä¢ Total fields returned by model: {batch_statistics['total_fields_returned']:,}\")\n        print(f\"   ‚Ä¢ Model response completeness: {overall_response_rate:.1f}% (fields returned)\")\n        print(f\"   ‚Ä¢ Content coverage of returned fields: {overall_content_rate:.1f}% (non-N/A values)\")\n        \n        # Per-image performance analysis\n        if not metadata_df.empty:\n            avg_response_completeness = metadata_df['_response_completeness'].mean()\n            avg_content_coverage = metadata_df['_content_coverage'].mean()\n            max_response = metadata_df['_response_completeness'].max()\n            min_response = metadata_df['_response_completeness'].min()\n            \n            print(f\"\\nüì∑ Per-Image Analysis (Corrected Metrics):\")\n            print(f\"   ‚Ä¢ Average fields returned per image: {avg_response_completeness:.1f}/{len(EXTRACTION_FIELDS)}\")\n            print(f\"   ‚Ä¢ Average content fields per image: {avg_content_coverage:.1f}\")\n            print(f\"   ‚Ä¢ Best model response: {max_response}/{len(EXTRACTION_FIELDS)} fields returned\")\n            print(f\"   ‚Ä¢ Worst model response: {min_response}/{len(EXTRACTION_FIELDS)} fields returned\")\n            \n            # Find best and worst performing images\n            best_idx = metadata_df['_response_completeness'].idxmax()\n            worst_idx = metadata_df['_response_completeness'].idxmin()\n            \n            best_image = metadata_df.loc[best_idx, 'image_name']\n            worst_image = metadata_df.loc[worst_idx, 'image_name']\n            \n            print(f\"   ‚Ä¢ Best performing image: {best_image} ({max_response} fields)\")\n            print(f\"   ‚Ä¢ Worst performing image: {worst_image} ({min_response} fields)\")\n        \n        # File size information\n        csv_size = csv_path.stat().st_size\n        print(f\"\\nüìä Output File Statistics:\")\n        print(f\"   ‚Ä¢ Main CSV file size: {csv_size:,} bytes\")\n        print(f\"   ‚Ä¢ Images with perfect model response (25/25): {len([r for r in extraction_results if r.get('_response_completeness', 0) == 25])}\")\n        print(f\"   ‚Ä¢ Images with partial model response (1-24): {len([r for r in extraction_results if 0 < r.get('_response_completeness', 0) < 25])}\")\n        print(f\"   ‚Ä¢ Images with no model response (0): {len([r for r in extraction_results if r.get('_response_completeness', 0) == 0])}\")\n        \n        print(f\"\\nüöÄ Enhanced batch processing completed successfully!\")\n        print(f\"üìÅ Results available at: {csv_path}\")\n        print(f\"‚úÖ Success metrics now correctly distinguish model response from field content\")\n        \n    except Exception as e:\n        print(f\"\\n‚ùå Error during batch processing: {e}\")\n        print(f\"üîç Error type: {type(e).__name__}\")\n        \n        import traceback\n        print(f\"\\nüîß Full error traceback:\")\n        traceback.print_exc()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "\"\"\"\nCell 5: Enhanced Data Analysis with Corrected Success Metrics\n\nPurpose:\n- Perform comprehensive analysis of CSV extraction results with accurate success tracking\n- Distinguish between Response Completeness (model returned keys) and Content Coverage (keys have values)\n- Validate data quality and provide insights for workflow optimization\n- Generate corrected field-level statistics and performance reports\n\nCorrected Analysis Components:\n1. CSV file validation and structural analysis\n2. Response completeness analysis (model performance)\n3. Content coverage analysis (field availability in documents)\n4. Enhanced quality metrics with proper success/failure classification\n\nEnhanced Quality Metrics:\n- Response Completeness: How many field keys the model actually returned (TRUE SUCCESS)\n- Content Coverage: How many returned keys have non-N/A values (CONTENT AVAILABILITY)\n- Field-level success rates: Which fields model consistently returns vs fails to return\n- Processing efficiency and error rate analysis with accurate classifications\n\nIntegration Support:\n- CSV structure validation for downstream systems\n- Corrected success rate reporting for model evaluation\n- Enhanced workflow optimization recommendations\n- Accurate extraction performance assessment\n\"\"\"\n\ntry:\n    # Verify CSV file exists and load for analysis\n    csv_path = Path(output_dir) / \"internvl3_batch_extraction.csv\"\n    \n    if not csv_path.exists():\n        print(\"‚ùå CSV file not found. Please run the batch processing cell first.\")\n    else:\n        print(\"üìä Loading CSV file for enhanced analysis with corrected metrics...\")\n        df_analysis = pd.read_csv(csv_path)\n        \n        print(f\"‚úÖ CSV loaded successfully: {len(df_analysis)} rows √ó {len(df_analysis.columns)} columns\")\n        \n        # Basic CSV structure validation\n        print(f\"\\nüîç CSV Structure Analysis:\")\n        print(f\"   ‚Ä¢ File size: {csv_path.stat().st_size:,} bytes\")\n        print(f\"   ‚Ä¢ Number of images processed: {len(df_analysis)}\")\n        print(f\"   ‚Ä¢ Number of extraction fields: {len(df_analysis.columns) - 1}\")  # -1 for image_name column\n        \n        # Column validation\n        expected_columns = ['image_name'] + EXTRACTION_FIELDS\n        actual_columns = list(df_analysis.columns)\n        \n        if actual_columns == expected_columns:\n            print(\"   ‚úÖ Column structure matches expected format\")\n        else:\n            print(\"   ‚ö†Ô∏è Column structure differs from expected format\")\n            print(f\"      Expected: {len(expected_columns)} columns\")\n            print(f\"      Actual: {len(actual_columns)} columns\")\n        \n        # Load metadata if available for enhanced analysis\n        metadata_files = list(Path(output_dir).glob(\"internvl3_extraction_metadata_*.csv\"))\n        metadata_df = None\n        \n        if metadata_files:\n            latest_metadata = max(metadata_files, key=lambda p: p.stat().st_mtime)\n            metadata_df = pd.read_csv(latest_metadata)\n            print(f\"   üìà Metadata loaded from: {latest_metadata.name}\")\n        \n        # Enhanced field-level analysis with corrected metrics\n        print(f\"\\nüìà Enhanced Field-Level Analysis (Corrected Success Metrics):\")\n        \n        if metadata_df is not None and len(metadata_df) == len(df_analysis):\n            # Use metadata for accurate success tracking\n            print(\"   üéØ Using enhanced success tracking from metadata\")\n            \n            # Calculate average response completeness and content coverage\n            avg_response_completeness = metadata_df['_response_completeness'].mean()\n            avg_content_coverage = metadata_df['_content_coverage'].mean()\n            \n            print(f\"\\n   üìä Overall Model Performance:\")\n            print(f\"      ‚Ä¢ Average fields returned per image: {avg_response_completeness:.1f}/{len(EXTRACTION_FIELDS)}\")\n            print(f\"      ‚Ä¢ Model response completeness: {(avg_response_completeness / len(EXTRACTION_FIELDS)) * 100:.1f}%\")\n            print(f\"      ‚Ä¢ Average content fields per image: {avg_content_coverage:.1f}\")\n            print(f\"      ‚Ä¢ Content coverage rate: {(avg_content_coverage / avg_response_completeness) * 100 if avg_response_completeness > 0 else 0:.1f}%\")\n            \n            # Distribution analysis\n            perfect_responses = len(metadata_df[metadata_df['_response_completeness'] == 25])\n            partial_responses = len(metadata_df[(metadata_df['_response_completeness'] > 0) & (metadata_df['_response_completeness'] < 25)])\n            failed_responses = len(metadata_df[metadata_df['_response_completeness'] == 0])\n            \n            print(f\"\\n   üìä Response Completeness Distribution:\")\n            print(f\"      ‚Ä¢ Perfect responses (25/25 fields): {perfect_responses} ({perfect_responses/len(metadata_df)*100:.1f}%)\")\n            print(f\"      ‚Ä¢ Partial responses (1-24 fields): {partial_responses} ({partial_responses/len(metadata_df)*100:.1f}%)\")\n            print(f\"      ‚Ä¢ Failed responses (0 fields): {failed_responses} ({failed_responses/len(metadata_df)*100:.1f}%)\")\n        \n        # Field-by-field analysis (traditional method as fallback)\n        print(f\"\\n   üìä Field-by-Field Content Analysis:\")\n        field_stats = {}\n        \n        for field in EXTRACTION_FIELDS:\n            if field in df_analysis.columns:\n                non_na_count = len(df_analysis[df_analysis[field] != 'N/A'])\n                content_rate = (non_na_count / len(df_analysis)) * 100\n                field_stats[field] = {\n                    'content_count': non_na_count,\n                    'content_rate': content_rate,\n                    'total_images': len(df_analysis)\n                }\n        \n        # Sort fields by content availability for insights\n        sorted_fields = sorted(field_stats.items(), key=lambda x: x[1]['content_rate'], reverse=True)\n        \n        print(\"      üìà Top 10 Fields with Most Content Available:\")\n        for i, (field, stats) in enumerate(sorted_fields[:10], 1):\n            print(f\"         {i:2d}. {field:<20} {stats['content_count']:3d}/{stats['total_images']:3d} ({stats['content_rate']:5.1f}% content)\")\n        \n        print(\"\\n      üìâ Bottom 5 Fields with Least Content Available:\")\n        for i, (field, stats) in enumerate(sorted_fields[-5:], len(sorted_fields)-4):\n            print(f\"         {i:2d}. {field:<20} {stats['content_count']:3d}/{stats['total_images']:3d} ({stats['content_rate']:5.1f}% content)\")\n        \n        # Overall extraction performance with corrected interpretation\n        total_possible_content = len(df_analysis) * len(EXTRACTION_FIELDS)\n        total_available_content = sum(stats['content_count'] for stats in field_stats.values())\n        overall_content_availability = (total_available_content / total_possible_content) * 100\n        \n        print(f\"\\nüéØ Corrected Performance Analysis:\")\n        print(f\"   ‚Ä¢ Total possible field instances: {total_possible_content:,}\")\n        print(f\"   ‚Ä¢ Total content available: {total_available_content:,}\")\n        print(f\"   ‚Ä¢ Overall content availability: {overall_content_availability:.1f}%\")\n        print(f\"   ‚Ä¢ Note: This measures document content, not model extraction success\")\n        \n        # Enhanced image-level analysis\n        image_content_performance = []\n        for _, row in df_analysis.iterrows():\n            content_fields = sum(1 for field in EXTRACTION_FIELDS if row[field] != 'N/A')\n            image_content_performance.append(content_fields)\n        \n        avg_content_per_image = sum(image_content_performance) / len(image_content_performance)\n        max_content = max(image_content_performance)\n        min_content = min(image_content_performance)\n        \n        print(f\"\\nüì∑ Per-Image Content Analysis:\")\n        print(f\"   ‚Ä¢ Average content fields per image: {avg_content_per_image:.1f}/{len(EXTRACTION_FIELDS)}\")\n        print(f\"   ‚Ä¢ Richest document: {max_content}/{len(EXTRACTION_FIELDS)} fields with content\")\n        print(f\"   ‚Ä¢ Sparsest document: {min_content}/{len(EXTRACTION_FIELDS)} fields with content\")\n        \n        # Identify richest and sparsest documents\n        df_with_content_performance = df_analysis.copy()\n        df_with_content_performance['content_fields'] = image_content_performance\n        \n        richest_image = df_with_content_performance.loc[df_with_content_performance['content_fields'].idxmax()]\n        sparsest_image = df_with_content_performance.loc[df_with_content_performance['content_fields'].idxmin()]\n        \n        print(f\"   ‚Ä¢ Richest document: {richest_image['image_name']} ({richest_image['content_fields']} fields)\")\n        print(f\"   ‚Ä¢ Sparsest document: {sparsest_image['image_name']} ({sparsest_image['content_fields']} fields)\")\n        \n        # Enhanced data quality validation\n        print(f\"\\nüîß Enhanced Data Quality Validation:\")\n        \n        # Check for completely empty documents (all N/A)\n        empty_documents = df_analysis[df_analysis[EXTRACTION_FIELDS].eq('N/A').all(axis=1)]\n        print(f\"   ‚Ä¢ Documents with no content: {len(empty_documents)}\")\n        \n        if len(empty_documents) > 0:\n            print(\"     üìÑ Documents with no extractable content:\")\n            for idx, row in empty_documents.head(3).iterrows():\n                print(f\"       - {row['image_name']}\")\n            if len(empty_documents) > 3:\n                print(f\"       ... and {len(empty_documents) - 3} more\")\n        \n        # Integration readiness assessment with corrected understanding\n        print(f\"\\nüöÄ Enhanced Integration Readiness Assessment:\")\n        \n        if metadata_df is not None:\n            # Use model performance metrics for readiness assessment\n            model_success_rate = (avg_response_completeness / len(EXTRACTION_FIELDS)) * 100\n            \n            if model_success_rate >= 95:\n                print(\"   ‚úÖ EXCELLENT - Model consistently returns structured fields\")\n            elif model_success_rate >= 80:\n                print(\"   ‚úÖ GOOD - Model reliably processes extraction requests\")\n            elif model_success_rate >= 60:\n                print(\"   ‚ö†Ô∏è FAIR - Model partially processes requests, some optimization needed\")\n            else:\n                print(\"   ‚ùå POOR - Model struggles with structured extraction format\")\n            \n            print(f\"   üìä Model Performance: {model_success_rate:.1f}% field return rate\")\n        else:\n            # Fallback to content-based assessment\n            if overall_content_availability >= 50:\n                print(\"   ‚úÖ GOOD - Documents contain substantial extractable content\")\n            elif overall_content_availability >= 30:\n                print(\"   ‚ö†Ô∏è FAIR - Documents have moderate content availability\")\n            else:\n                print(\"   ‚ùå SPARSE - Documents contain limited extractable content\")\n        \n        print(f\"\\nüìÅ Enhanced CSV File Details:\")\n        print(f\"   ‚Ä¢ Main file: {csv_path}\")\n        print(f\"   ‚Ä¢ File format: UTF-8 encoded CSV\")\n        print(f\"   ‚Ä¢ Column separator: comma (,)\")\n        print(f\"   ‚Ä¢ Missing value representation: N/A\")\n        print(f\"   ‚Ä¢ Success metrics: Corrected to distinguish model performance from content availability\")\n        print(f\"   ‚Ä¢ Ready for: Database import, spreadsheet analysis, API integration\")\n        \n        print(f\"\\n‚úÖ Enhanced data analysis completed with corrected success metrics!\")\n        print(f\"üìà Key insight: Success now properly measured by model field return rate, not content availability\")\n        \nexcept FileNotFoundError:\n    print(\"‚ùå CSV file not found for analysis\")\n    print(\"üí° Please run the batch processing cell first to generate the CSV\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Error during enhanced data analysis: {e}\")\n    print(f\"üîç Error type: {type(e).__name__}\")\n    \n    import traceback\n    print(f\"\\nüîß Full error traceback:\")\n    traceback.print_exc()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nCell 5: Advanced Data Analysis and CSV Validation\n\nPurpose:\n- Perform comprehensive analysis of the generated CSV extraction results\n- Validate data quality and provide insights for workflow optimization\n- Generate detailed field-level statistics and coverage reports\n\nAnalysis Components:\n1. CSV file validation and structural analysis\n2. Field-by-field coverage and content analysis\n3. Data quality metrics and extraction performance\n4. Export validation and integration readiness assessment\n\nQuality Metrics:\n- Field completeness rates across all processed images\n- Most/least successfully extracted field types\n- Data consistency and format validation\n- Processing efficiency and error rate analysis\n\nIntegration Support:\n- CSV structure validation for downstream systems\n- Data type consistency verification\n- Missing value pattern analysis\n- Export format compliance checking\n\"\"\"\n\ntry:\n    # Verify CSV file exists and load for analysis\n    csv_path = Path(output_dir) / \"internvl3_batch_extraction.csv\"\n    \n    if not csv_path.exists():\n        print(\"‚ùå CSV file not found. Please run the batch processing cell first.\")\n    else:\n        print(\"üìä Loading CSV file for comprehensive analysis...\")\n        df_analysis = pd.read_csv(csv_path)\n        \n        print(f\"‚úÖ CSV loaded successfully: {len(df_analysis)} rows √ó {len(df_analysis.columns)} columns\")\n        \n        # Basic CSV structure validation\n        print(f\"\\nüîç CSV Structure Analysis:\")\n        print(f\"   ‚Ä¢ File size: {csv_path.stat().st_size:,} bytes\")\n        print(f\"   ‚Ä¢ Number of images processed: {len(df_analysis)}\")\n        print(f\"   ‚Ä¢ Number of extraction fields: {len(df_analysis.columns) - 1}\")  # -1 for image_name column\n        \n        # Column validation\n        expected_columns = ['image_name'] + EXTRACTION_FIELDS\n        actual_columns = list(df_analysis.columns)\n        \n        if actual_columns == expected_columns:\n            print(\"   ‚úÖ Column structure matches expected format\")\n        else:\n            print(\"   ‚ö†Ô∏è Column structure differs from expected format\")\n            print(f\"      Expected: {len(expected_columns)} columns\")\n            print(f\"      Actual: {len(actual_columns)} columns\")\n        \n        # Field-level analysis\n        print(f\"\\nüìà Field-Level Coverage Analysis:\")\n        field_stats = {}\n        \n        for field in EXTRACTION_FIELDS:\n            if field in df_analysis.columns:\n                non_na_count = len(df_analysis[df_analysis[field] != 'N/A'])\n                coverage_rate = (non_na_count / len(df_analysis)) * 100\n                field_stats[field] = {\n                    'coverage_count': non_na_count,\n                    'coverage_rate': coverage_rate,\n                    'total_images': len(df_analysis)\n                }\n        \n        # Sort fields by coverage rate for better insights\n        sorted_fields = sorted(field_stats.items(), key=lambda x: x[1]['coverage_rate'], reverse=True)\n        \n        print(\"   üìä Top 10 Most Successfully Extracted Fields:\")\n        for i, (field, stats) in enumerate(sorted_fields[:10], 1):\n            print(f\"      {i:2d}. {field:<20} {stats['coverage_count']:3d}/{stats['total_images']:3d} ({stats['coverage_rate']:5.1f}%)\")\n        \n        print(\"\\n   üìä Bottom 5 Least Successfully Extracted Fields:\")\n        for i, (field, stats) in enumerate(sorted_fields[-5:], len(sorted_fields)-4):\n            print(f\"      {i:2d}. {field:<20} {stats['coverage_count']:3d}/{stats['total_images']:3d} ({stats['coverage_rate']:5.1f}%)\")\n        \n        # Overall extraction performance\n        total_possible_fields = len(df_analysis) * len(EXTRACTION_FIELDS)\n        total_extracted_fields = sum(stats['coverage_count'] for stats in field_stats.values())\n        overall_extraction_rate = (total_extracted_fields / total_possible_fields) * 100\n        \n        print(f\"\\nüéØ Overall Extraction Performance:\")\n        print(f\"   ‚Ä¢ Total possible field extractions: {total_possible_fields:,}\")\n        print(f\"   ‚Ä¢ Total successful field extractions: {total_extracted_fields:,}\")\n        print(f\"   ‚Ä¢ Overall extraction success rate: {overall_extraction_rate:.1f}%\")\n        \n        # Image-level analysis\n        image_performance = []\n        for _, row in df_analysis.iterrows():\n            extracted_fields = sum(1 for field in EXTRACTION_FIELDS if row[field] != 'N/A')\n            image_performance.append(extracted_fields)\n        \n        avg_fields_per_image = sum(image_performance) / len(image_performance)\n        max_fields = max(image_performance)\n        min_fields = min(image_performance)\n        \n        print(f\"\\nüì∑ Per-Image Extraction Analysis:\")\n        print(f\"   ‚Ä¢ Average fields extracted per image: {avg_fields_per_image:.1f}/{len(EXTRACTION_FIELDS)}\")\n        print(f\"   ‚Ä¢ Best performing image: {max_fields}/{len(EXTRACTION_FIELDS)} fields\")\n        print(f\"   ‚Ä¢ Worst performing image: {min_fields}/{len(EXTRACTION_FIELDS)} fields\")\n        \n        # Identify best and worst performing images\n        df_with_performance = df_analysis.copy()\n        df_with_performance['extracted_fields'] = image_performance\n        \n        best_image = df_with_performance.loc[df_with_performance['extracted_fields'].idxmax()]\n        worst_image = df_with_performance.loc[df_with_performance['extracted_fields'].idxmin()]\n        \n        print(f\"   ‚Ä¢ Best performing image: {best_image['image_name']} ({best_image['extracted_fields']} fields)\")\n        print(f\"   ‚Ä¢ Worst performing image: {worst_image['image_name']} ({worst_image['extracted_fields']} fields)\")\n        \n        # Data consistency checks\n        print(f\"\\nüîß Data Quality Validation:\")\n        \n        # Check for completely empty rows (all N/A except image_name)\n        empty_rows = df_analysis[df_analysis[EXTRACTION_FIELDS].eq('N/A').all(axis=1)]\n        print(f\"   ‚Ä¢ Images with no extracted fields: {len(empty_rows)}\")\n        \n        if len(empty_rows) > 0:\n            print(\"     Failed images:\")\n            for idx, row in empty_rows.head(3).iterrows():\n                print(f\"       - {row['image_name']}\")\n            if len(empty_rows) > 3:\n                print(f\"       ... and {len(empty_rows) - 3} more\")\n        \n        # Integration readiness assessment\n        print(f\"\\nüöÄ Integration Readiness Assessment:\")\n        if overall_extraction_rate >= 80:\n            print(\"   ‚úÖ EXCELLENT - High extraction success rate, ready for production\")\n        elif overall_extraction_rate >= 60:\n            print(\"   ‚úÖ GOOD - Acceptable extraction rate, suitable for most applications\")\n        elif overall_extraction_rate >= 40:\n            print(\"   ‚ö†Ô∏è FAIR - Moderate extraction rate, consider process optimization\")\n        else:\n            print(\"   ‚ùå POOR - Low extraction rate, requires investigation and improvement\")\n        \n        print(f\"\\nüìÅ CSV File Details:\")\n        print(f\"   ‚Ä¢ Main file: {csv_path}\")\n        print(f\"   ‚Ä¢ File format: UTF-8 encoded CSV\")\n        print(f\"   ‚Ä¢ Column separator: comma (,)\")\n        print(f\"   ‚Ä¢ Missing value representation: N/A\")\n        print(f\"   ‚Ä¢ Ready for: Database import, spreadsheet analysis, API integration\")\n        \n        print(f\"\\n‚úÖ Data analysis completed successfully!\")\n        \nexcept FileNotFoundError:\n    print(\"‚ùå CSV file not found for analysis\")\n    print(\"üí° Please run the batch processing cell first to generate the CSV\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Error during data analysis: {e}\")\n    print(f\"üîç Error type: {type(e).__name__}\")\n    \n    import traceback\n    print(f\"\\nüîß Full error traceback:\")\n    traceback.print_exc()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell 5: Results Saving and Analysis Pipeline\n",
    "\n",
    "Purpose:\n",
    "- Save extracted key-value pairs to persistent storage for further processing\n",
    "- Perform quality analysis and validation of extraction results\n",
    "- Generate extraction reports and statistics for workflow integration\n",
    "\n",
    "File Operations:\n",
    "- Creates output directory using global output_dir configuration\n",
    "- Uses UTF-8 encoding for proper international character handling\n",
    "- Saves with descriptive filename including timestamp capability\n",
    "- Implements atomic file operations to prevent data corruption\n",
    "\n",
    "Quality Analysis Features:\n",
    "- Field completeness assessment (target: 25 fields)\n",
    "- Content validation for required field formats\n",
    "- Data quality indicators for downstream processing\n",
    "- Extraction confidence metrics and reporting\n",
    "\n",
    "Error Handling:\n",
    "- NameError: Handles case where response variable isn't defined\n",
    "- FileSystem errors: Permission issues, disk space, path problems\n",
    "- Encoding errors: Character set and formatting issues\n",
    "- Provides actionable troubleshooting guidance for each error type\n",
    "\n",
    "Integration Features:\n",
    "- Structured output suitable for database import\n",
    "- JSON-compatible field parsing for API integration\n",
    "- Batch processing support for multiple document workflows\n",
    "\"\"\"\n",
    "\n",
    "# Configure output path using global output_dir variable\n",
    "output_filename = \"internvl3_keyvalue_extraction.txt\"\n",
    "output_path = Path(output_dir) / output_filename\n",
    "\n",
    "print(f\"üíæ Saving extraction results to: {output_path}\")\n",
    "\n",
    "try:\n",
    "    # Ensure output directory exists with proper permissions\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Write extraction results with UTF-8 encoding for international support\n",
    "    with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "        text_file.write(response)\n",
    "    \n",
    "    print(f\"‚úÖ Key-value extraction results saved successfully!\")\n",
    "    print(f\"üìÑ File location: {output_path}\")\n",
    "    print(f\"üìä File size: {output_path.stat().st_size} bytes\")\n",
    "    \n",
    "    # Advanced extraction analysis and reporting\n",
    "    lines = response.split('\\n')\n",
    "    field_lines = [line for line in lines if ':' in line and not line.strip().startswith('<')]\n",
    "    \n",
    "    print(f\"\\nüìà Detailed Extraction Analysis:\")\n",
    "    print(f\"   ‚Ä¢ Document processed: {document_image}\")\n",
    "    print(f\"   ‚Ä¢ Total response lines: {len(lines)}\")\n",
    "    print(f\"   ‚Ä¢ Structured field lines: {len(field_lines)}\")\n",
    "    print(f\"   ‚Ä¢ Field extraction rate: {len(field_lines)/25*100:.1f}%\")\n",
    "    \n",
    "    # Field content analysis\n",
    "    non_na_fields = [line for line in field_lines if not line.split(':')[1].strip().upper() in ['N/A', 'NA']]\n",
    "    print(f\"   ‚Ä¢ Fields with content: {len(non_na_fields)}\")\n",
    "    print(f\"   ‚Ä¢ Content coverage: {len(non_na_fields)/25*100:.1f}%\")\n",
    "    \n",
    "    # File validation\n",
    "    file_size = output_path.stat().st_size\n",
    "    if file_size > 100:\n",
    "        print(\"‚úÖ Output file validation: PASSED (sufficient content)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Output file validation: WARNING (minimal content detected)\")\n",
    "    \n",
    "    print(f\"\\nüîó Integration ready: Results saved in structured format\")\n",
    "    print(f\"üìÅ Output directory: {output_dir}\")\n",
    "    \n",
    "except NameError:\n",
    "    print(\"‚ùå Error: Extraction response not available\")\n",
    "    print(\"üí° Solution: Execute Cell 4 first to generate extraction results\")\n",
    "    print(\"üîÑ Then re-run this cell to save the results\")\n",
    "    \n",
    "except PermissionError:\n",
    "    print(f\"‚ùå Permission Error: Cannot write to {output_path}\")\n",
    "    print(\"üí° Solutions:\")\n",
    "    print(\"   ‚Ä¢ Check directory write permissions\")\n",
    "    print(\"   ‚Ä¢ Verify output_dir path is accessible\")\n",
    "    print(\"   ‚Ä¢ Try running with appropriate user permissions\")\n",
    "    \n",
    "except OSError as e:\n",
    "    print(f\"‚ùå File System Error: {e}\")\n",
    "    print(\"üí° Solutions:\")\n",
    "    print(\"   ‚Ä¢ Check available disk space\")\n",
    "    print(\"   ‚Ä¢ Verify path validity and accessibility\")\n",
    "    print(\"   ‚Ä¢ Ensure parent directories exist\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Unexpected error during file operations: {e}\")\n",
    "    print(f\"üîç Error type: {type(e).__name__}\")\n",
    "    print(\"üí° Check system resources and file path configuration\")\n",
    "    print(f\"üóÇÔ∏è Configured output directory: {output_dir}\")\n",
    "    \n",
    "    import traceback\n",
    "    print(f\"\\nüîß Full error details:\")\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (unified_vision_processor)",
   "language": "python",
   "name": "unified_vision_processor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}