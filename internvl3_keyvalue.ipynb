{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nCell 1: Environment Setup and Model Loading for Key-Value Extraction\n\nPurpose:\n- Import all required libraries for InternVL3-2B vision-language model\n- Load the InternVL3-2B model optimized for structured key-value extraction\n- Initialize model with proper dtype and CUDA settings for inference\n- Define global configuration variables for data paths\n\nKey Components:\n- torch.bfloat16: Memory-efficient 16-bit floating point for better performance\n- trust_remote_code=True: Allow loading custom model code from HuggingFace\n- use_fast=False: Use slower but more reliable tokenizer for structured output\n- .eval().cuda(): Set model to evaluation mode and move to GPU\n\nGlobal Configuration:\n- data_dir: Centralized data directory path for all image operations\n- model_path: Local path to InternVL3-2B model files\n- output_dir: Directory for saving extraction results\n\nSpecialized for Key-Value Extraction:\n- Optimized for structured document processing\n- Configured for deterministic, consistent field extraction\n- Designed for business document analysis workflows\n\"\"\"\n\nfrom pathlib import Path\nimport torch\nfrom PIL import Image\nfrom transformers import AutoModel, AutoTokenizer\nimport torchvision.transforms as T\n\n# Global configuration variables\ndata_dir = \"/home/jovyan/nfs_share/tod/huaifeng_data\"\nmodel_path = \"/home/jovyan/nfs_share/models/InternVL3-2B\" \noutput_dir = \"/home/jovyan/nfs_share/tod/output\"\n\nprint(f\"üóÇÔ∏è  Data directory: {data_dir}\")\nprint(f\"üìÅ Output directory: {output_dir}\")\nprint(f\"üîß Loading InternVL3-2B model for key-value extraction from: {model_path}\")\n\n# Load model with official recommended settings for structured extraction\nmodel = AutoModel.from_pretrained(\n    model_path,\n    torch_dtype=torch.bfloat16,  # Use bfloat16 for memory efficiency\n    low_cpu_mem_usage=True,      # Optimize CPU memory during loading\n    trust_remote_code=True       # Allow custom model code execution\n).eval().cuda()                  # Set to evaluation mode and move to GPU\n\n# Load tokenizer with settings optimized for structured output\ntokenizer = AutoTokenizer.from_pretrained(\n    model_path, \n    trust_remote_code=True,  # Allow custom tokenizer code\n    use_fast=False          # Use slower but more reliable tokenizer for structured tasks\n)\n\nprint(\"‚úÖ Model and tokenizer loaded successfully for key-value extraction\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nCell 2: Dynamic Image Processing Pipeline for Document Analysis\n\nPurpose:\n- Implement complete InternVL3 dynamic image preprocessing with optimal tiling\n- Support advanced features like aspect ratio optimization for better text recognition\n- Handle various document formats with intelligent preprocessing\n\nDynamic Preprocessing Features:\n1. build_transform(): Creates transformation pipeline with BICUBIC interpolation\n2. find_closest_aspect_ratio(): Optimizes image tiling based on document dimensions\n3. dynamic_preprocess(): Intelligently tiles documents for better text understanding\n4. load_image(): Complete image loading with dynamic preprocessing support\n\nDocument Processing Advantages:\n- Optimal aspect ratio detection for text-heavy documents\n- Dynamic tiling preserves document structure and readability\n- Minimizes information loss through intelligent cropping\n- Handles various document orientations and layouts\n- Max tiles configuration prevents memory overflow\n\"\"\"\n\nimport math\n\n# ImageNet normalization constants for optimal model performance\nIMAGENET_MEAN = (0.485, 0.456, 0.406)\nIMAGENET_STD = (0.229, 0.224, 0.225)\n\ndef build_transform(input_size):\n    \"\"\"\n    Build image transformation pipeline optimized for document analysis\n    \n    Args:\n        input_size: Target size for image resizing\n    \n    Returns:\n        torchvision.transforms.Compose: Complete transformation pipeline\n    \"\"\"\n    MEAN, STD = IMAGENET_MEAN, IMAGENET_STD\n    transform = T.Compose([\n        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n        T.Resize((input_size, input_size), interpolation=T.InterpolationMode.BICUBIC),\n        T.ToTensor(),\n        T.Normalize(mean=MEAN, std=STD)\n    ])\n    return transform\n\ndef find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n    \"\"\"\n    Find optimal aspect ratio for document tiling to minimize text information loss\n    \n    Args:\n        aspect_ratio: Original document aspect ratio (width/height)\n        target_ratios: List of possible grid ratios [(w,h), ...]\n        width, height: Original document dimensions\n        image_size: Target tile size\n    \n    Returns:\n        tuple: Optimal (width_tiles, height_tiles) configuration\n    \"\"\"\n    best_ratio_diff = float('inf')\n    best_ratio = (1, 1)\n    area = width * height\n    for ratio in target_ratios:\n        target_aspect_ratio = ratio[0] / ratio[1]\n        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n        if ratio_diff < best_ratio_diff:\n            best_ratio_diff = ratio_diff\n            best_ratio = ratio\n        elif ratio_diff == best_ratio_diff:\n            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n                best_ratio = ratio\n    return best_ratio\n\ndef dynamic_preprocess(image, min_num=1, max_num=12, image_size=448, use_thumbnail=False):\n    \"\"\"\n    Dynamically preprocess document into optimal tile configuration for text extraction\n    \n    Args:\n        image: PIL Image object of the document\n        min_num: Minimum number of tiles\n        max_num: Maximum number of tiles (prevents memory overflow)\n        image_size: Size of each tile\n        use_thumbnail: Whether to add thumbnail for multi-tile scenarios\n    \n    Returns:\n        list: List of processed document tiles optimized for text recognition\n    \"\"\"\n    orig_width, orig_height = image.size\n    aspect_ratio = orig_width / orig_height\n\n    # Calculate optimal tiling strategy for document layout\n    target_ratios = set(\n        (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if\n        i * j <= max_num and i * j >= min_num)\n    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n\n    # Find the closest aspect ratio to preserve document structure\n    target_aspect_ratio = find_closest_aspect_ratio(\n        aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n\n    # Calculate target dimensions for optimal text preservation\n    target_width = image_size * target_aspect_ratio[0]\n    target_height = image_size * target_aspect_ratio[1]\n    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n\n    # Resize document maintaining text quality\n    resized_img = image.resize((target_width, target_height))\n    processed_images = []\n    \n    for i in range(blocks):\n        box = (\n            (i % (target_width // image_size)) * image_size,\n            (i // (target_width // image_size)) * image_size,\n            ((i % (target_width // image_size)) + 1) * image_size,\n            ((i // (target_width // image_size)) + 1) * image_size\n        )\n        # Split document into tiles preserving text regions\n        split_img = resized_img.crop(box)\n        processed_images.append(split_img)\n    \n    assert len(processed_images) == blocks\n    \n    if use_thumbnail and len(processed_images) != 1:\n        thumbnail_img = image.resize((image_size, image_size))\n        processed_images.append(thumbnail_img)\n    \n    return processed_images\n\ndef load_image(image_path, input_size=448, max_num=12):\n    \"\"\"\n    Load and preprocess document with dynamic tiling for optimal text extraction\n    \n    Args:\n        image_path: Path to document file (relative to data_dir or absolute)\n        input_size: Target size for each tile\n        max_num: Maximum number of tiles to generate (prevents memory issues)\n    \n    Returns:\n        torch.Tensor: Stacked tensor of processed document tiles\n    \"\"\"\n    # Handle both relative and absolute paths\n    if not image_path.startswith('/'):\n        image_path = f\"{data_dir}/{image_path}\"\n    \n    image = Image.open(image_path).convert('RGB')\n    transform = build_transform(input_size=input_size)\n    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n    pixel_values = [transform(image) for image in images]\n    pixel_values = torch.stack(pixel_values)\n    return pixel_values\n\n# Load and process document with dynamic tiling for optimal extraction\ndocument_image = \"synthetic_invoice_014.png\"  # Configurable document filename\nprint(f\"üìÑ Loading document from: {data_dir}/{document_image}\")\n\n# Load original image for analysis\nimage_path = f\"{data_dir}/{document_image}\"\noriginal_image = Image.open(image_path)\nprint(f\"üì∑ Original document size: {original_image.size}\")\nprint(f\"üìê Document aspect ratio: {original_image.size[0]/original_image.size[1]:.2f}\")\n\n# Process with dynamic tiling for optimal text extraction\nprint(\"üñºÔ∏è  Processing document with dynamic tiling...\")\npixel_values = load_image(document_image, max_num=12)\nprint(f\"‚úÖ Document processed into {pixel_values.shape[0]} tiles: {pixel_values.shape}\")\nprint(\"üîç Document optimally tiled for comprehensive field extraction\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nCell 3: Structured Key-Value Extraction Prompt Configuration\n\nPurpose:\n- Define comprehensive prompt for extracting structured business document data\n- Configure extraction parameters for consistent, standardized output\n- Specify exact output format requirements for downstream processing\n\nExtraction Specifications:\n- 25 predefined fields covering common business document types\n- Supports invoices, receipts, bank statements, and tax documents\n- Handles missing fields gracefully with \"N/A\" placeholders\n- Enforces plain text output without markdown formatting\n- Ensures deterministic field ordering for automated processing\n\nField Categories:\n1. Document metadata (type, dates)\n2. Supplier/business information (name, address, contact)\n3. Financial data (amounts, GST, totals)\n4. Transaction details (quantities, prices, descriptions)\n5. Banking information (account numbers, BSB, balances)\n\nOutput Quality Controls:\n- Explicit formatting rules to prevent markdown artifacts\n- Character limits and validation requirements\n- Structured field validation for downstream systems\n\"\"\"\n\n# Comprehensive key-value extraction prompt optimized for business documents\nextraction_prompt = \"\"\"Extract data from this business document. \nOutput ALL fields below with their exact keys. \nUse \"N/A\" if field is not visible or not present.\n\nREQUIRED OUTPUT FORMAT (output ALL lines exactly as shown):\nDOCUMENT_TYPE: [value or N/A]\nSUPPLIER: [value or N/A]\nABN: [11-digit Australian Business Number or N/A]\nPAYER_NAME: [value or N/A]\nPAYER_ADDRESS: [value or N/A]\nPAYER_PHONE: [value or N/A]\nPAYER_EMAIL: [value or N/A]\nINVOICE_DATE: [value or N/A]\nDUE_DATE: [value or N/A]\nGST: [GST amount in dollars or N/A]\nTOTAL: [total amount in dollars or N/A]\nSUBTOTAL: [subtotal amount in dollars or N/A]\nSUPPLIER_WEBSITE: [value or N/A]\nQUANTITIES: [list of quantities or N/A]\nPRICES: [individual prices in dollars or N/A]\nBUSINESS_ADDRESS: [value or N/A]\nBUSINESS_PHONE: [value or N/A]\nBANK_NAME: [bank name from bank statements only or N/A]\nBSB_NUMBER: [6-digit BSB from bank statements only or N/A]\nBANK_ACCOUNT_NUMBER: [account number from bank statements only or N/A]\nACCOUNT_HOLDER: [value or N/A]\nSTATEMENT_PERIOD: [value or N/A]\nOPENING_BALANCE: [opening balance amount in dollars or N/A]\nCLOSING_BALANCE: [closing balance amount in dollars or N/A]\nDESCRIPTIONS: [list of transaction descriptions or N/A]\n\nCRITICAL: Output in PLAIN TEXT format only. Do NOT use markdown formatting.\n\nCORRECT format: DOCUMENT_TYPE: TAX INVOICE\nWRONG format: **DOCUMENT_TYPE:** TAX INVOICE\nWRONG format: **DOCUMENT_TYPE: TAX INVOICE**\nWRONG format: DOCUMENT_TYPE: **TAX INVOICE**\n\nUse exactly: KEY: value (with colon and space)\nNever use: **KEY:** or **KEY** or any asterisks\nNever use bold, italic, or any markdown formatting\n\nABSOLUTELY CRITICAL: Output EXACTLY 25 lines using ONLY the keys listed above. \nDo NOT add extra fields like \\\"Balance\\\", \\\"Credit\\\", \\\"Debit\\\", \\\"Date\\\", \\\"Description\\\".\nDo NOT include ANY fields not in the required list above.\nInclude ALL 25 keys listed above even if value is N/A.\nSTOP after exactly 25 lines.\"\"\"\n\n# Format prompt for InternVL3 with proper image token\nquestion = f'<image>\\n{extraction_prompt}'\n\nprint(\"üìã Structured key-value extraction prompt configured\")\nprint(f\"üìÑ Prompt length: {len(extraction_prompt)} characters\")\nprint(f\"üîç Extracting 25 standardized business document fields\")\nprint(\"‚öôÔ∏è Configured for deterministic, structured output\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nCell 4: Key-Value Extraction Execution and Processing\n\nPurpose:\n- Execute structured field extraction using optimized generation parameters\n- Process document with InternVL3 model for consistent key-value pairs\n- Handle extraction errors gracefully with comprehensive error reporting\n\nGeneration Configuration:\n- max_new_tokens=1000: Sufficient for 25 structured fields\n- do_sample=False: Deterministic output for consistent field extraction\n- pad_token_id=tokenizer.eos_token_id: Prevents padding warnings\n- Temperature disabled: Ensures reproducible extraction results\n\nError Handling:\n- Comprehensive exception catching with detailed error reporting\n- Type-specific error identification for debugging\n- Stack trace output for development troubleshooting\n- Graceful failure with actionable error messages\n\nOutput Validation:\n- Field count verification (should extract exactly 25 fields)\n- Format validation for downstream processing\n- Quality indicators for extraction success assessment\n\"\"\"\n\n# Generation configuration optimized for structured output\ngeneration_config = dict(\n    max_new_tokens=1000,                    # Adequate tokens for 25 structured fields\n    do_sample=False,                        # Deterministic for consistent field extraction\n    pad_token_id=tokenizer.eos_token_id     # Prevent pad_token_id warnings\n    # Note: Temperature omitted since do_sample=False\n)\n\nprint(\"ü§ñ Executing key-value extraction with InternVL3...\")\nprint(\"‚öôÔ∏è Using deterministic generation for consistent field extraction\")\n\ntry:\n    # Execute structured field extraction\n    response = model.chat(tokenizer, pixel_values, question, generation_config)\n    \n    print(\"‚úÖ Key-value extraction completed successfully!\")\n    print(\"\\n\" + \"=\"*60)\n    print(\"EXTRACTED BUSINESS DOCUMENT FIELDS:\")\n    print(\"=\"*60)\n    print(response)\n    print(\"=\"*60)\n    \n    # Basic validation of extraction results\n    lines = response.split('\\n')\n    field_lines = [line for line in lines if ':' in line and not line.strip().startswith('<')]\n    print(f\"\\nüìä Extraction Statistics:\")\n    print(f\"   ‚Ä¢ Total field lines extracted: {len(field_lines)}\")\n    print(f\"   ‚Ä¢ Expected field count: 25\")\n    print(f\"   ‚Ä¢ Extraction completeness: {len(field_lines)/25*100:.1f}%\")\n    \n    if len(field_lines) == 25:\n        print(\"‚úÖ Perfect field extraction - all 25 fields captured\")\n    elif len(field_lines) > 0:\n        print(\"‚ö†Ô∏è Partial extraction - some fields may be missing\")\n    else:\n        print(\"‚ùå No structured fields detected in response\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Error during key-value extraction: {e}\")\n    print(f\"üîç Error type: {type(e).__name__}\")\n    print(\"\\nüìã Troubleshooting suggestions:\")\n    print(\"   ‚Ä¢ Check document image quality and readability\")\n    print(\"   ‚Ä¢ Verify model and tokenizer are properly loaded\")\n    print(\"   ‚Ä¢ Ensure sufficient GPU memory for processing\")\n    print(\"   ‚Ä¢ Validate document contains extractable text fields\")\n    \n    import traceback\n    print(f\"\\nüîß Full error traceback:\")\n    traceback.print_exc()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nCell 5: Results Saving and Analysis Pipeline\n\nPurpose:\n- Save extracted key-value pairs to persistent storage for further processing\n- Perform quality analysis and validation of extraction results\n- Generate extraction reports and statistics for workflow integration\n\nFile Operations:\n- Creates output directory using global output_dir configuration\n- Uses UTF-8 encoding for proper international character handling\n- Saves with descriptive filename including timestamp capability\n- Implements atomic file operations to prevent data corruption\n\nQuality Analysis Features:\n- Field completeness assessment (target: 25 fields)\n- Content validation for required field formats\n- Data quality indicators for downstream processing\n- Extraction confidence metrics and reporting\n\nError Handling:\n- NameError: Handles case where response variable isn't defined\n- FileSystem errors: Permission issues, disk space, path problems\n- Encoding errors: Character set and formatting issues\n- Provides actionable troubleshooting guidance for each error type\n\nIntegration Features:\n- Structured output suitable for database import\n- JSON-compatible field parsing for API integration\n- Batch processing support for multiple document workflows\n\"\"\"\n\n# Configure output path using global output_dir variable\noutput_filename = \"internvl3_keyvalue_extraction.txt\"\noutput_path = Path(output_dir) / output_filename\n\nprint(f\"üíæ Saving extraction results to: {output_path}\")\n\ntry:\n    # Ensure output directory exists with proper permissions\n    output_path.parent.mkdir(parents=True, exist_ok=True)\n    \n    # Write extraction results with UTF-8 encoding for international support\n    with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n        text_file.write(response)\n    \n    print(f\"‚úÖ Key-value extraction results saved successfully!\")\n    print(f\"üìÑ File location: {output_path}\")\n    print(f\"üìä File size: {output_path.stat().st_size} bytes\")\n    \n    # Advanced extraction analysis and reporting\n    lines = response.split('\\n')\n    field_lines = [line for line in lines if ':' in line and not line.strip().startswith('<')]\n    \n    print(f\"\\nüìà Detailed Extraction Analysis:\")\n    print(f\"   ‚Ä¢ Document processed: {document_image}\")\n    print(f\"   ‚Ä¢ Total response lines: {len(lines)}\")\n    print(f\"   ‚Ä¢ Structured field lines: {len(field_lines)}\")\n    print(f\"   ‚Ä¢ Field extraction rate: {len(field_lines)/25*100:.1f}%\")\n    \n    # Field content analysis\n    non_na_fields = [line for line in field_lines if not line.split(':')[1].strip().upper() in ['N/A', 'NA']]\n    print(f\"   ‚Ä¢ Fields with content: {len(non_na_fields)}\")\n    print(f\"   ‚Ä¢ Content coverage: {len(non_na_fields)/25*100:.1f}%\")\n    \n    # File validation\n    file_size = output_path.stat().st_size\n    if file_size > 100:\n        print(\"‚úÖ Output file validation: PASSED (sufficient content)\")\n    else:\n        print(\"‚ö†Ô∏è Output file validation: WARNING (minimal content detected)\")\n    \n    print(f\"\\nüîó Integration ready: Results saved in structured format\")\n    print(f\"üìÅ Output directory: {output_dir}\")\n    \nexcept NameError:\n    print(\"‚ùå Error: Extraction response not available\")\n    print(\"üí° Solution: Execute Cell 4 first to generate extraction results\")\n    print(\"üîÑ Then re-run this cell to save the results\")\n    \nexcept PermissionError:\n    print(f\"‚ùå Permission Error: Cannot write to {output_path}\")\n    print(\"üí° Solutions:\")\n    print(\"   ‚Ä¢ Check directory write permissions\")\n    print(\"   ‚Ä¢ Verify output_dir path is accessible\")\n    print(\"   ‚Ä¢ Try running with appropriate user permissions\")\n    \nexcept OSError as e:\n    print(f\"‚ùå File System Error: {e}\")\n    print(\"üí° Solutions:\")\n    print(\"   ‚Ä¢ Check available disk space\")\n    print(\"   ‚Ä¢ Verify path validity and accessibility\")\n    print(\"   ‚Ä¢ Ensure parent directories exist\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Unexpected error during file operations: {e}\")\n    print(f\"üîç Error type: {type(e).__name__}\")\n    print(\"üí° Check system resources and file path configuration\")\n    print(f\"üóÇÔ∏è Configured output directory: {output_dir}\")\n    \n    import traceback\n    print(f\"\\nüîß Full error details:\")\n    traceback.print_exc()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}